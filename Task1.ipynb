{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "print(\"--- Step 1: Loading the Dataset ---\")\n",
        "try:\n",
        "    df = pd.read_csv('Dataset .csv')\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'Dataset .csv' not found. Please ensure the file is in the correct directory.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Initial dataset shape: {df.shape}\")\n",
        "print(\"Initial 5 rows:\")\n",
        "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# --- 2. Handle Missing Values ---\n",
        "print(\"\\n--- Step 2: Handling Missing Values ---\")\n",
        "print(\"Missing values before handling:\")\n",
        "print(df.isnull().sum()[df.isnull().sum() > 0].to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "# Drop rows with missing values in 'Cuisines' (only 9 missing, small percentage)\n",
        "df.dropna(subset=['Cuisines'], inplace=True)\n",
        "print(f\"Dataset shape after dropping rows with missing 'Cuisines': {df.shape}\")\n",
        "print(\"Missing values after handling:\")\n",
        "print(df.isnull().sum()[df.isnull().sum() > 0].to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# --- 3. Encode Categorical Variables ---\n",
        "print(\"\\n--- Step 3: Encoding Categorical Variables ---\")\n",
        "\n",
        "# Convert binary 'Yes'/'No' columns to 1/0\n",
        "binary_cols = ['Has Table booking', 'Has Online delivery', 'Is delivering now', 'Switch to order menu']\n",
        "for col in binary_cols:\n",
        "    df[col] = df[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "print(\"Binary 'Yes'/'No' columns converted to 1/0.\")\n",
        "print(df[binary_cols].head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# Store the original categorical columns for later use with new data in prediction\n",
        "# These lists are crucial for consistent preprocessing of new data\n",
        "global original_categorical_cols_for_ohe\n",
        "original_categorical_cols_for_ohe = ['Country Code', 'City', 'Currency']\n",
        "global original_binary_cols_for_new_data\n",
        "original_binary_cols_for_new_data = ['Has Table booking', 'Has Online delivery', 'Is delivering now']\n",
        "global original_all_cuisines # To ensure all possible cuisine columns are created\n",
        "original_all_cuisines = sorted(df['Cuisines'].str.split(', ').explode().unique())\n",
        "\n",
        "\n",
        "# Drop high cardinality and redundant columns, AND NOW ALSO Rating color and Rating text\n",
        "columns_to_drop_for_training = [\n",
        "    'Restaurant Name',\n",
        "    'Address',\n",
        "    'Locality',\n",
        "    'Locality Verbose',\n",
        "    'Switch to order menu', # This column only has '0' after conversion\n",
        "    'Rating color',         # EXCLUDING THIS FEATURE\n",
        "    'Rating text'           # EXCLUDING THIS FEATURE\n",
        "]\n",
        "df.drop(columns=columns_to_drop_for_training, inplace=True)\n",
        "print(f\"Dropped high cardinality/redundant columns, including Rating Color/Text. Current shape: {df.shape}\")\n",
        "\n",
        "\n",
        "# One-Hot Encode other nominal categorical columns\n",
        "df = pd.get_dummies(df, columns=original_categorical_cols_for_ohe, drop_first=True)\n",
        "print(f\"Nominal categorical columns one-hot encoded. Current shape: {df.shape}\")\n",
        "\n",
        "\n",
        "# Handle 'Cuisines' column with multi-label one-hot encoding\n",
        "cuisine_dummies = df['Cuisines'].str.get_dummies(sep=', ')\n",
        "df = pd.concat([df, cuisine_dummies], axis=1)\n",
        "df.drop(columns=['Cuisines'], inplace=True)\n",
        "print(f\"'Cuisines' column multi-label encoded. Current shape: {df.shape}\")\n",
        "\n",
        "\n",
        "# --- 4. Separate Features (X) and Target (y) ---\n",
        "print(\"\\n--- Step 4: Separating Features (X) and Target (y) ---\")\n",
        "if 'Restaurant ID' in df.columns:\n",
        "    X = df.drop(columns=['Aggregate rating', 'Restaurant ID'])\n",
        "else:\n",
        "    X = df.drop(columns=['Aggregate rating'])\n",
        "y = df['Aggregate rating']\n",
        "\n",
        "print(f\"Shape of features (X): {X.shape}\")\n",
        "print(f\"Shape of target (y): {y.shape}\")\n",
        "print(\"First 5 rows of X (before scaling numerical features):\")\n",
        "print(X.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "print(\"First 5 rows of y:\")\n",
        "print(y.head().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# --- 5. Feature Scaling ---\n",
        "print(\"\\n--- Step 5: Feature Scaling ---\")\n",
        "global numerical_cols_to_scale # Make it global for prediction function\n",
        "numerical_cols_to_scale = ['Longitude', 'Latitude', 'Average Cost for two', 'Price range', 'Votes']\n",
        "numerical_cols_to_scale = [col for col in numerical_cols_to_scale if col in X.columns]\n",
        "\n",
        "global scaler # Make scaler global for prediction function\n",
        "scaler = StandardScaler()\n",
        "X[numerical_cols_to_scale] = scaler.fit_transform(X[numerical_cols_to_scale])\n",
        "print(\"Numerical features scaled using StandardScaler.\")\n",
        "print(\"First 5 rows of X (after scaling numerical features):\")\n",
        "print(X.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# --- 6. Splitting the Data into Training and Testing Sets ---\n",
        "print(\"\\n--- Step 6: Splitting Data into Training and Testing Sets ---\")\n",
        "global X_train, X_test, y_train, y_test # Make these global for subsequent cells\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "print(\"\\nPreprocessing complete! The data is now ready for model training.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm3i2026kjcp",
        "outputId": "168ac16a-e033-4d42-95d1-c737d873b61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Loading the Dataset ---\n",
            "Dataset loaded successfully!\n",
            "Initial dataset shape: (9551, 21)\n",
            "Initial 5 rows:\n",
            "| Restaurant ID   | Restaurant Name        | Country Code   | City             | Address                                                                 | Locality                                   | Locality Verbose                                             | Longitude   | Latitude   | Cuisines                         | Average Cost for two   | Currency         | Has Table booking   | Has Online delivery   | Is delivering now   | Switch to order menu   | Price range   | Aggregate rating   | Rating color   | Rating text   | Votes   |\n",
            "|:----------------|:-----------------------|:---------------|:-----------------|:------------------------------------------------------------------------|:-------------------------------------------|:-------------------------------------------------------------|:------------|:-----------|:---------------------------------|:-----------------------|:-----------------|:--------------------|:----------------------|:--------------------|:-----------------------|:--------------|:-------------------|:---------------|:--------------|:--------|\n",
            "| 6317637         | Le Petit Souffle       | 162            | Makati City      | Third Floor, Century City Mall, Kalayaan Avenue, Poblacion, Makati City | Century City Mall, Poblacion, Makati City  | Century City Mall, Poblacion, Makati City, Makati City       | 121.028     | 14.5654    | French, Japanese, Desserts       | 1100                   | Botswana Pula(P) | Yes                 | No                    | No                  | No                     | 3             | 4.8                | Dark Green     | Excellent     | 314     |\n",
            "| 6304287         | Izakaya Kikufuji       | 162            | Makati City      | Little Tokyo, 2277 Chino Roces Avenue, Legaspi Village, Makati City     | Little Tokyo, Legaspi Village, Makati City | Little Tokyo, Legaspi Village, Makati City, Makati City      | 121.014     | 14.5537    | Japanese                         | 1200                   | Botswana Pula(P) | Yes                 | No                    | No                  | No                     | 3             | 4.5                | Dark Green     | Excellent     | 591     |\n",
            "| 6300002         | Heat - Edsa Shangri-La | 162            | Mandaluyong City | Edsa Shangri-La, 1 Garden Way, Ortigas, Mandaluyong City                | Edsa Shangri-La, Ortigas, Mandaluyong City | Edsa Shangri-La, Ortigas, Mandaluyong City, Mandaluyong City | 121.057     | 14.5814    | Seafood, Asian, Filipino, Indian | 4000                   | Botswana Pula(P) | Yes                 | No                    | No                  | No                     | 4             | 4.4                | Green          | Very Good     | 270     |\n",
            "| 6318506         | Ooma                   | 162            | Mandaluyong City | Third Floor, Mega Fashion Hall, SM Megamall, Ortigas, Mandaluyong City  | SM Megamall, Ortigas, Mandaluyong City     | SM Megamall, Ortigas, Mandaluyong City, Mandaluyong City     | 121.056     | 14.5853    | Japanese, Sushi                  | 1500                   | Botswana Pula(P) | No                  | No                    | No                  | No                     | 4             | 4.9                | Dark Green     | Excellent     | 365     |\n",
            "| 6314302         | Sambo Kojin            | 162            | Mandaluyong City | Third Floor, Mega Atrium, SM Megamall, Ortigas, Mandaluyong City        | SM Megamall, Ortigas, Mandaluyong City     | SM Megamall, Ortigas, Mandaluyong City, Mandaluyong City     | 121.058     | 14.5845    | Japanese, Korean                 | 1500                   | Botswana Pula(P) | Yes                 | No                    | No                  | No                     | 4             | 4.8                | Dark Green     | Excellent     | 229     |\n",
            "\n",
            "--- Step 2: Handling Missing Values ---\n",
            "Missing values before handling:\n",
            "|          | 0   |\n",
            "|:---------|:----|\n",
            "| Cuisines | 9   |\n",
            "Dataset shape after dropping rows with missing 'Cuisines': (9542, 21)\n",
            "Missing values after handling:\n",
            "| 0   |\n",
            "|-----|\n",
            "\n",
            "--- Step 3: Encoding Categorical Variables ---\n",
            "Binary 'Yes'/'No' columns converted to 1/0.\n",
            "| Has Table booking   | Has Online delivery   | Is delivering now   | Switch to order menu   |\n",
            "|:--------------------|:----------------------|:--------------------|:-----------------------|\n",
            "| 1                   | 0                     | 0                   | 0                      |\n",
            "| 1                   | 0                     | 0                   | 0                      |\n",
            "| 1                   | 0                     | 0                   | 0                      |\n",
            "| 0                   | 0                     | 0                   | 0                      |\n",
            "| 1                   | 0                     | 0                   | 0                      |\n",
            "Dropped high cardinality/redundant columns, including Rating Color/Text. Current shape: (9542, 14)\n",
            "Nominal categorical columns one-hot encoded. Current shape: (9542, 175)\n",
            "'Cuisines' column multi-label encoded. Current shape: (9542, 319)\n",
            "\n",
            "--- Step 4: Separating Features (X) and Target (y) ---\n",
            "Shape of features (X): (9542, 317)\n",
            "Shape of target (y): (9542,)\n",
            "First 5 rows of X (before scaling numerical features):\n",
            "| Longitude   | Latitude   | Average Cost for two   | Has Table booking   | Has Online delivery   | Is delivering now   | Price range   | Votes   | Country Code_14   | Country Code_30   | Country Code_37   | Country Code_94   | Country Code_148   | Country Code_162   | Country Code_166   | Country Code_184   | Country Code_189   | Country Code_191   | Country Code_208   | Country Code_214   | Country Code_215   | Country Code_216   | City_Agra   | City_Ahmedabad   | City_Albany   | City_Allahabad   | City_Amritsar   | City_Ankara   | City_Armidale   | City_Athens   | City_Auckland   | City_Augusta   | City_Aurangabad   | City_Balingup   | City_Bandung   | City_Bangalore   | City_Beechworth   | City_Bhopal   | City_Bhubaneshwar   | City_Birmingham   | City_Bogor   | City_Boise   | City_Bras�_lia   | City_Cape Town   | City_Cedar Rapids/Iowa City   | City_Chandigarh   | City_Chatham-Kent   | City_Chennai   | City_Clatskanie   | City_Cochrane   | City_Coimbatore   | City_Colombo   | City_Columbus   | City_Consort   | City_Dalton   | City_Davenport   | City_Dehradun   | City_Des Moines   | City_Dicky Beach   | City_Doha   | City_Dubai   | City_Dubuque   | City_East Ballina   | City_Edinburgh   | City_Faridabad   | City_Fernley   | City_Flaxton   | City_Forrest   | City_Gainesville   | City_Ghaziabad   | City_Goa   | City_Gurgaon   | City_Guwahati   | City_Hepburn Springs   | City_Huskisson   | City_Hyderabad   | City_Indore   | City_Inner City   | City_Inverloch   | City_Jaipur   | City_Jakarta   | City_Johannesburg   | City_Kanpur   | City_Kochi   | City_Kolkata   | City_Lakes Entrance   | City_Lakeview   | City_Lincoln   | City_London   | City_Lorn   | City_Lucknow   | City_Ludhiana   | City_Macedon   | City_Macon   | City_Makati City   | City_Manchester   | City_Mandaluyong City   | City_Mangalore   | City_Mayfield   | City_Mc Millan   | City_Middleton Beach   | City_Mohali   | City_Monroe   | City_Montville   | City_Mumbai   | City_Mysore   | City_Nagpur   | City_Nashik   | City_New Delhi   | City_Noida   | City_Ojo Caliente   | City_Orlando   | City_Palm Cove   | City_Panchkula   | City_Pasay City   | City_Pasig City   | City_Patna   | City_Paynesville   | City_Penola   | City_Pensacola   | City_Phillip Island   | City_Pocatello   | City_Potrero   | City_Pretoria   | City_Princeton   | City_Puducherry   | City_Pune   | City_Quezon City   | City_Ranchi   | City_Randburg   | City_Rest of Hawaii   | City_Rio de Janeiro   | City_San Juan City   | City_Sandton   | City_Santa Rosa   | City_Savannah   | City_Secunderabad   | City_Sharjah   | City_Singapore   | City_Sioux City   | City_Surat   | City_S��o Paulo   | City_Tagaytay City   | City_Taguig City   | City_Tampa Bay   | City_Tangerang   | City_Tanunda   | City_Trentham East   | City_Vadodara   | City_Valdosta   | City_Varanasi   | City_Vernonia   | City_Victor Harbor   | City_Vineland Station   | City_Vizag   | City_Waterloo   | City_Weirton   | City_Wellington City   | City_Winchester Bay   | City_Yorkton   | City_��stanbul   | Currency_Brazilian Real(R$)   | Currency_Dollar($)   | Currency_Emirati Diram(AED)   | Currency_Indian Rupees(Rs.)   | Currency_Indonesian Rupiah(IDR)   | Currency_NewZealand($)   | Currency_Pounds(��)   | Currency_Qatari Rial(QR)   | Currency_Rand(R)   | Currency_Sri Lankan Rupee(LKR)   | Currency_Turkish Lira(TL)   | Afghani   | African   | American   | Andhra   | Arabian   | Argentine   | Armenian   | Asian   | Asian Fusion   | Assamese   | Australian   | Awadhi   | BBQ   | Bakery   | Bar Food   | Belgian   | Bengali   | Beverages   | Bihari   | Biryani   | Brazilian   | Breakfast   | British   | Bubble Tea   | Burger   | Burmese   | B�_rek   | Cafe   | Cajun   | Canadian   | Cantonese   | Caribbean   | Charcoal Grill   | Chettinad   | Chinese   | Coffee and Tea   | Contemporary   | Continental   | Cuban   | Cuisine Varies   | Curry   | Deli   | Desserts   | Dim Sum   | Diner   | Drinks Only   | Durban   | D�_ner   | European   | Fast Food   | Filipino   | Finger Food   | Fish and Chips   | French   | Fusion   | German   | Goan   | Gourmet Fast Food   | Greek   | Grill   | Gujarati   | Hawaiian   | Healthy Food   | Hyderabadi   | Ice Cream   | Indian   | Indonesian   | International   | Iranian   | Irish   | Italian   | Izgara   | Japanese   | Juices   | Kashmiri   | Kebab   | Kerala   | Kiwi   | Korean   | Latin American   | Lebanese   | Lucknowi   | Maharashtrian   | Malay   | Malaysian   | Malwani   | Mangalorean   | Mediterranean   | Mexican   | Middle Eastern   | Mineira   | Mithai   | Modern Australian   | Modern Indian   | Moroccan   | Mughlai   | Naga   | Nepalese   | New American   | North Eastern   | North Indian   | Oriya   | Pakistani   | Parsi   | Patisserie   | Peranakan   | Persian   | Peruvian   | Pizza   | Portuguese   | Pub Food   | Rajasthani   | Ramen   | Raw Meats   | Restaurant Cafe   | Salad   | Sandwich   | Scottish   | Seafood   | Singaporean   | Soul Food   | South African   | South American   | South Indian   | Southern   | Southwestern   | Spanish   | Sri Lankan   | Steak   | Street Food   | Sunda   | Sushi   | Taiwanese   | Tapas   | Tea   | Teriyaki   | Tex-Mex   | Thai   | Tibetan   | Turkish   | Turkish Pizza   | Vegetarian   | Vietnamese   | Western   | World Cuisine   |\n",
            "|:------------|:-----------|:-----------------------|:--------------------|:----------------------|:--------------------|:--------------|:--------|:------------------|:------------------|:------------------|:------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:------------|:-----------------|:--------------|:-----------------|:----------------|:--------------|:----------------|:--------------|:----------------|:---------------|:------------------|:----------------|:---------------|:-----------------|:------------------|:--------------|:--------------------|:------------------|:-------------|:-------------|:-----------------|:-----------------|:------------------------------|:------------------|:--------------------|:---------------|:------------------|:----------------|:------------------|:---------------|:----------------|:---------------|:--------------|:-----------------|:----------------|:------------------|:-------------------|:------------|:-------------|:---------------|:--------------------|:-----------------|:-----------------|:---------------|:---------------|:---------------|:-------------------|:-----------------|:-----------|:---------------|:----------------|:-----------------------|:-----------------|:-----------------|:--------------|:------------------|:-----------------|:--------------|:---------------|:--------------------|:--------------|:-------------|:---------------|:----------------------|:----------------|:---------------|:--------------|:------------|:---------------|:----------------|:---------------|:-------------|:-------------------|:------------------|:------------------------|:-----------------|:----------------|:-----------------|:-----------------------|:--------------|:--------------|:-----------------|:--------------|:--------------|:--------------|:--------------|:-----------------|:-------------|:--------------------|:---------------|:-----------------|:-----------------|:------------------|:------------------|:-------------|:-------------------|:--------------|:-----------------|:----------------------|:-----------------|:---------------|:----------------|:-----------------|:------------------|:------------|:-------------------|:--------------|:----------------|:----------------------|:----------------------|:---------------------|:---------------|:------------------|:----------------|:--------------------|:---------------|:-----------------|:------------------|:-------------|:------------------|:---------------------|:-------------------|:-----------------|:-----------------|:---------------|:---------------------|:----------------|:----------------|:----------------|:----------------|:---------------------|:------------------------|:-------------|:----------------|:---------------|:-----------------------|:----------------------|:---------------|:-----------------|:------------------------------|:---------------------|:------------------------------|:------------------------------|:----------------------------------|:-------------------------|:----------------------|:---------------------------|:-------------------|:---------------------------------|:----------------------------|:----------|:----------|:-----------|:---------|:----------|:------------|:-----------|:--------|:---------------|:-----------|:-------------|:---------|:------|:---------|:-----------|:----------|:----------|:------------|:---------|:----------|:------------|:------------|:----------|:-------------|:---------|:----------|:---------|:-------|:--------|:-----------|:------------|:------------|:-----------------|:------------|:----------|:-----------------|:---------------|:--------------|:--------|:-----------------|:--------|:-------|:-----------|:----------|:--------|:--------------|:---------|:---------|:-----------|:------------|:-----------|:--------------|:-----------------|:---------|:---------|:---------|:-------|:--------------------|:--------|:--------|:-----------|:-----------|:---------------|:-------------|:------------|:---------|:-------------|:----------------|:----------|:--------|:----------|:---------|:-----------|:---------|:-----------|:--------|:---------|:-------|:---------|:-----------------|:-----------|:-----------|:----------------|:--------|:------------|:----------|:--------------|:----------------|:----------|:-----------------|:----------|:---------|:--------------------|:----------------|:-----------|:----------|:-------|:-----------|:---------------|:----------------|:---------------|:--------|:------------|:--------|:-------------|:------------|:----------|:-----------|:--------|:-------------|:-----------|:-------------|:--------|:------------|:------------------|:--------|:-----------|:-----------|:----------|:--------------|:------------|:----------------|:-----------------|:---------------|:-----------|:---------------|:----------|:-------------|:--------|:--------------|:--------|:--------|:------------|:--------|:------|:-----------|:----------|:-------|:----------|:----------|:----------------|:-------------|:-------------|:----------|:----------------|\n",
            "| 121.028     | 14.5654    | 1100                   | 1                   | 0                     | 0                   | 3             | 314     | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | True               | False             | False                   | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | 0         | 0         | 0          | 0        | 0         | 0           | 0          | 0       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 1          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 0          | 0             | 0                | 1        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 0        | 0            | 0               | 0         | 0       | 0         | 0        | 1          | 0        | 0          | 0       | 0        | 0      | 0        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 0         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 0       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "| 121.014     | 14.5537    | 1200                   | 1                   | 0                     | 0                   | 3             | 591     | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | True               | False             | False                   | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | 0         | 0         | 0          | 0        | 0         | 0           | 0          | 0       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 0          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 0          | 0             | 0                | 0        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 0        | 0            | 0               | 0         | 0       | 0         | 0        | 1          | 0        | 0          | 0       | 0        | 0      | 0        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 0         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 0       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "| 121.057     | 14.5814    | 4000                   | 1                   | 0                     | 0                   | 4             | 270     | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | False              | False             | True                    | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | 0         | 0         | 0          | 0        | 0         | 0           | 0          | 1       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 0          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 1          | 0             | 0                | 0        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 1        | 0            | 0               | 0         | 0       | 0         | 0        | 0          | 0        | 0          | 0       | 0        | 0      | 0        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 1         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 0       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "| 121.056     | 14.5853    | 1500                   | 0                   | 0                     | 0                   | 4             | 365     | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | False              | False             | True                    | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | 0         | 0         | 0          | 0        | 0         | 0           | 0          | 0       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 0          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 0          | 0             | 0                | 0        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 0        | 0            | 0               | 0         | 0       | 0         | 0        | 1          | 0        | 0          | 0       | 0        | 0      | 0        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 0         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 1       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "| 121.058     | 14.5845    | 1500                   | 1                   | 0                     | 0                   | 4             | 229     | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | False              | False             | True                    | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | 0         | 0         | 0          | 0        | 0         | 0           | 0          | 0       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 0          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 0          | 0             | 0                | 0        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 0        | 0            | 0               | 0         | 0       | 0         | 0        | 1          | 0        | 0          | 0       | 0        | 0      | 1        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 0         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 0       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "First 5 rows of y:\n",
            "|    | Aggregate rating   |\n",
            "|:---|:-------------------|\n",
            "| 0  | 4.8                |\n",
            "| 1  | 4.5                |\n",
            "| 2  | 4.4                |\n",
            "| 3  | 4.9                |\n",
            "| 4  | 4.8                |\n",
            "\n",
            "--- Step 5: Feature Scaling ---\n",
            "Numerical features scaled using StandardScaler.\n",
            "First 5 rows of X (after scaling numerical features):\n",
            "| Longitude   | Latitude   | Average Cost for two   | Has Table booking   | Has Online delivery   | Is delivering now   | Price range   | Votes    | Country Code_14   | Country Code_30   | Country Code_37   | Country Code_94   | Country Code_148   | Country Code_162   | Country Code_166   | Country Code_184   | Country Code_189   | Country Code_191   | Country Code_208   | Country Code_214   | Country Code_215   | Country Code_216   | City_Agra   | City_Ahmedabad   | City_Albany   | City_Allahabad   | City_Amritsar   | City_Ankara   | City_Armidale   | City_Athens   | City_Auckland   | City_Augusta   | City_Aurangabad   | City_Balingup   | City_Bandung   | City_Bangalore   | City_Beechworth   | City_Bhopal   | City_Bhubaneshwar   | City_Birmingham   | City_Bogor   | City_Boise   | City_Bras�_lia   | City_Cape Town   | City_Cedar Rapids/Iowa City   | City_Chandigarh   | City_Chatham-Kent   | City_Chennai   | City_Clatskanie   | City_Cochrane   | City_Coimbatore   | City_Colombo   | City_Columbus   | City_Consort   | City_Dalton   | City_Davenport   | City_Dehradun   | City_Des Moines   | City_Dicky Beach   | City_Doha   | City_Dubai   | City_Dubuque   | City_East Ballina   | City_Edinburgh   | City_Faridabad   | City_Fernley   | City_Flaxton   | City_Forrest   | City_Gainesville   | City_Ghaziabad   | City_Goa   | City_Gurgaon   | City_Guwahati   | City_Hepburn Springs   | City_Huskisson   | City_Hyderabad   | City_Indore   | City_Inner City   | City_Inverloch   | City_Jaipur   | City_Jakarta   | City_Johannesburg   | City_Kanpur   | City_Kochi   | City_Kolkata   | City_Lakes Entrance   | City_Lakeview   | City_Lincoln   | City_London   | City_Lorn   | City_Lucknow   | City_Ludhiana   | City_Macedon   | City_Macon   | City_Makati City   | City_Manchester   | City_Mandaluyong City   | City_Mangalore   | City_Mayfield   | City_Mc Millan   | City_Middleton Beach   | City_Mohali   | City_Monroe   | City_Montville   | City_Mumbai   | City_Mysore   | City_Nagpur   | City_Nashik   | City_New Delhi   | City_Noida   | City_Ojo Caliente   | City_Orlando   | City_Palm Cove   | City_Panchkula   | City_Pasay City   | City_Pasig City   | City_Patna   | City_Paynesville   | City_Penola   | City_Pensacola   | City_Phillip Island   | City_Pocatello   | City_Potrero   | City_Pretoria   | City_Princeton   | City_Puducherry   | City_Pune   | City_Quezon City   | City_Ranchi   | City_Randburg   | City_Rest of Hawaii   | City_Rio de Janeiro   | City_San Juan City   | City_Sandton   | City_Santa Rosa   | City_Savannah   | City_Secunderabad   | City_Sharjah   | City_Singapore   | City_Sioux City   | City_Surat   | City_S��o Paulo   | City_Tagaytay City   | City_Taguig City   | City_Tampa Bay   | City_Tangerang   | City_Tanunda   | City_Trentham East   | City_Vadodara   | City_Valdosta   | City_Varanasi   | City_Vernonia   | City_Victor Harbor   | City_Vineland Station   | City_Vizag   | City_Waterloo   | City_Weirton   | City_Wellington City   | City_Winchester Bay   | City_Yorkton   | City_��stanbul   | Currency_Brazilian Real(R$)   | Currency_Dollar($)   | Currency_Emirati Diram(AED)   | Currency_Indian Rupees(Rs.)   | Currency_Indonesian Rupiah(IDR)   | Currency_NewZealand($)   | Currency_Pounds(��)   | Currency_Qatari Rial(QR)   | Currency_Rand(R)   | Currency_Sri Lankan Rupee(LKR)   | Currency_Turkish Lira(TL)   | Afghani   | African   | American   | Andhra   | Arabian   | Argentine   | Armenian   | Asian   | Asian Fusion   | Assamese   | Australian   | Awadhi   | BBQ   | Bakery   | Bar Food   | Belgian   | Bengali   | Beverages   | Bihari   | Biryani   | Brazilian   | Breakfast   | British   | Bubble Tea   | Burger   | Burmese   | B�_rek   | Cafe   | Cajun   | Canadian   | Cantonese   | Caribbean   | Charcoal Grill   | Chettinad   | Chinese   | Coffee and Tea   | Contemporary   | Continental   | Cuban   | Cuisine Varies   | Curry   | Deli   | Desserts   | Dim Sum   | Diner   | Drinks Only   | Durban   | D�_ner   | European   | Fast Food   | Filipino   | Finger Food   | Fish and Chips   | French   | Fusion   | German   | Goan   | Gourmet Fast Food   | Greek   | Grill   | Gujarati   | Hawaiian   | Healthy Food   | Hyderabadi   | Ice Cream   | Indian   | Indonesian   | International   | Iranian   | Irish   | Italian   | Izgara   | Japanese   | Juices   | Kashmiri   | Kebab   | Kerala   | Kiwi   | Korean   | Latin American   | Lebanese   | Lucknowi   | Maharashtrian   | Malay   | Malaysian   | Malwani   | Mangalorean   | Mediterranean   | Mexican   | Middle Eastern   | Mineira   | Mithai   | Modern Australian   | Modern Indian   | Moroccan   | Mughlai   | Naga   | Nepalese   | New American   | North Eastern   | North Indian   | Oriya   | Pakistani   | Parsi   | Patisserie   | Peranakan   | Persian   | Peruvian   | Pizza   | Portuguese   | Pub Food   | Rajasthani   | Ramen   | Raw Meats   | Restaurant Cafe   | Salad   | Sandwich   | Scottish   | Seafood   | Singaporean   | Soul Food   | South African   | South American   | South Indian   | Southern   | Southwestern   | Spanish   | Sri Lankan   | Steak   | Street Food   | Sunda   | Sushi   | Taiwanese   | Tapas   | Tea   | Teriyaki   | Tex-Mex   | Thai   | Tibetan   | Turkish   | Turkish Pizza   | Vegetarian   | Vietnamese   | Western   | World Cuisine   |\n",
            "|:------------|:-----------|:-----------------------|:--------------------|:----------------------|:--------------------|:--------------|:---------|:------------------|:------------------|:------------------|:------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:------------|:-----------------|:--------------|:-----------------|:----------------|:--------------|:----------------|:--------------|:----------------|:---------------|:------------------|:----------------|:---------------|:-----------------|:------------------|:--------------|:--------------------|:------------------|:-------------|:-------------|:-----------------|:-----------------|:------------------------------|:------------------|:--------------------|:---------------|:------------------|:----------------|:------------------|:---------------|:----------------|:---------------|:--------------|:-----------------|:----------------|:------------------|:-------------------|:------------|:-------------|:---------------|:--------------------|:-----------------|:-----------------|:---------------|:---------------|:---------------|:-------------------|:-----------------|:-----------|:---------------|:----------------|:-----------------------|:-----------------|:-----------------|:--------------|:------------------|:-----------------|:--------------|:---------------|:--------------------|:--------------|:-------------|:---------------|:----------------------|:----------------|:---------------|:--------------|:------------|:---------------|:----------------|:---------------|:-------------|:-------------------|:------------------|:------------------------|:-----------------|:----------------|:-----------------|:-----------------------|:--------------|:--------------|:-----------------|:--------------|:--------------|:--------------|:--------------|:-----------------|:-------------|:--------------------|:---------------|:-----------------|:-----------------|:------------------|:------------------|:-------------|:-------------------|:--------------|:-----------------|:----------------------|:-----------------|:---------------|:----------------|:-----------------|:------------------|:------------|:-------------------|:--------------|:----------------|:----------------------|:----------------------|:---------------------|:---------------|:------------------|:----------------|:--------------------|:---------------|:-----------------|:------------------|:-------------|:------------------|:---------------------|:-------------------|:-----------------|:-----------------|:---------------|:---------------------|:----------------|:----------------|:----------------|:----------------|:---------------------|:------------------------|:-------------|:----------------|:---------------|:-----------------------|:----------------------|:---------------|:-----------------|:------------------------------|:---------------------|:------------------------------|:------------------------------|:----------------------------------|:-------------------------|:----------------------|:---------------------------|:-------------------|:---------------------------------|:----------------------------|:----------|:----------|:-----------|:---------|:----------|:------------|:-----------|:--------|:---------------|:-----------|:-------------|:---------|:------|:---------|:-----------|:----------|:----------|:------------|:---------|:----------|:------------|:------------|:----------|:-------------|:---------|:----------|:---------|:-------|:--------|:-----------|:------------|:------------|:-----------------|:------------|:----------|:-----------------|:---------------|:--------------|:--------|:-----------------|:--------|:-------|:-----------|:----------|:--------|:--------------|:---------|:---------|:-----------|:------------|:-----------|:--------------|:-----------------|:---------|:---------|:---------|:-------|:--------------------|:--------|:--------|:-----------|:-----------|:---------------|:-------------|:------------|:---------|:-------------|:----------------|:----------|:--------|:----------|:---------|:-----------|:---------|:-----------|:--------|:---------|:-------|:---------|:-----------------|:-----------|:-----------|:----------------|:--------|:------------|:----------|:--------------|:----------------|:----------|:-----------------|:----------|:---------|:--------------------|:----------------|:-----------|:----------|:-------|:-----------|:---------------|:----------------|:---------------|:--------|:------------|:--------|:-------------|:------------|:----------|:-----------|:--------|:-------------|:-----------|:-------------|:--------|:------------|:------------------|:--------|:-----------|:-----------|:----------|:--------------|:------------|:----------------|:-----------------|:---------------|:-----------|:---------------|:----------|:-------------|:--------|:--------------|:--------|:--------|:------------|:--------|:------|:-----------|:----------|:-------|:----------|:----------|:----------------|:-------------|:-------------|:----------|:----------------|\n",
            "| 1.37764     | -1.02485   | -0.00622066            | 1                   | 0                     | 0                   | 1.31973       | 0.365493 | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | True               | False             | False                   | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | 0         | 0         | 0          | 0        | 0         | 0           | 0          | 0       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 1          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 0          | 0             | 0                | 1        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 0        | 0            | 0               | 0         | 0       | 0         | 0        | 1          | 0        | 0          | 0       | 0        | 0      | 0        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 0         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 0       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "| 1.37732     | -1.02591   | -2.02219e-05           | 1                   | 0                     | 0                   | 1.31973       | 1.00941  | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | True               | False             | False                   | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | 0         | 0         | 0          | 0        | 0         | 0           | 0          | 0       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 0          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 0          | 0             | 0                | 0        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 0        | 0            | 0               | 0         | 0       | 0         | 0        | 1          | 0        | 0          | 0       | 0        | 0      | 0        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 0         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 0       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "| 1.37835     | -1.0234    | 0.173592               | 1                   | 0                     | 0                   | 2.42407       | 0.26321  | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | False              | False             | True                    | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | 0         | 0         | 0          | 0        | 0         | 0           | 0          | 1       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 0          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 1          | 0             | 0                | 0        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 1        | 0            | 0               | 0         | 0       | 0         | 0        | 0          | 0        | 0          | 0       | 0        | 0      | 0        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 1         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 0       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "| 1.37834     | -1.02304   | 0.0185811              | 0                   | 0                     | 0                   | 2.42407       | 0.484048 | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | False              | False             | True                    | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | 0         | 0         | 0          | 0        | 0         | 0           | 0          | 0       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 0          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 0          | 0             | 0                | 0        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 0        | 0            | 0               | 0         | 0       | 0         | 0        | 1          | 0        | 0          | 0       | 0        | 0      | 0        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 0         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 1       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "| 1.37837     | -1.02312   | 0.0185811              | 1                   | 0                     | 0                   | 2.42407       | 0.167901 | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | False              | False             | True                    | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | 0         | 0         | 0          | 0        | 0         | 0           | 0          | 0       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 0          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 0          | 0             | 0                | 0        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 0        | 0            | 0               | 0         | 0       | 0         | 0        | 1          | 0        | 0          | 0       | 0        | 0      | 1        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 0         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 0       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "\n",
            "--- Step 6: Splitting Data into Training and Testing Sets ---\n",
            "X_train shape: (7633, 317)\n",
            "X_test shape: (1909, 317)\n",
            "y_train shape: (7633,)\n",
            "y_test shape: (1909,)\n",
            "\n",
            "Preprocessing complete! The data is now ready for model training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# --- Model Selection and Training ---\n",
        "print(\"\\n--- Step: Selecting and Training Regression Algorithms ---\")\n",
        "\n",
        "# 1. Linear Regression Model\n",
        "print(\"\\nTraining Linear Regression Model...\")\n",
        "global linear_reg_model # Make global for potential future use\n",
        "linear_reg_model = LinearRegression()\n",
        "linear_reg_model.fit(X_train, y_train)\n",
        "print(\"Linear Regression Model trained successfully!\")\n",
        "\n",
        "# 2. Random Forest Regressor Model\n",
        "print(\"\\nTraining Random Forest Regressor Model...\")\n",
        "global random_forest_model # Make random_forest_model global for prediction function\n",
        "random_forest_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "print(\"Random Forest Regressor Model trained successfully!\")\n",
        "\n",
        "print(\"\\nBoth regression models are now trained and ready for evaluation.\")\n",
        "\n",
        "# Store models for later use\n",
        "trained_models = {\n",
        "    \"Linear Regression\": linear_reg_model,\n",
        "    \"Random Forest Regressor\": random_forest_model\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jokdjJwmbVi",
        "outputId": "90fad4fc-5687-4572-b126-f593536c9f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step: Selecting and Training Regression Algorithms ---\n",
            "\n",
            "Training Linear Regression Model...\n",
            "Linear Regression Model trained successfully!\n",
            "\n",
            "Training Random Forest Regressor Model...\n",
            "Random Forest Regressor Model trained successfully!\n",
            "\n",
            "Both regression models are now trained and ready for evaluation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "print(\"\\n--- Step: Evaluating Model Performance ---\")\n",
        "\n",
        "# 1. Evaluate Linear Regression Model\n",
        "print(\"\\nEvaluating Linear Regression Model:\")\n",
        "y_pred_lr = linear_reg_model.predict(X_test)\n",
        "global mse_lr, r2_lr # Make global for Cell 4 summary\n",
        "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
        "r2_lr = r2_score(y_test, y_pred_lr)\n",
        "\n",
        "print(f\"  Mean Squared Error (MSE): {mse_lr:.4f}\")\n",
        "print(f\"  R-squared (R2): {r2_lr:.4f}\")\n",
        "\n",
        "# 2. Evaluate Random Forest Regressor Model\n",
        "print(\"\\nEvaluating Random Forest Regressor Model:\")\n",
        "y_pred_rf = random_forest_model.predict(X_test)\n",
        "global mse_rf, r2_rf # Make global for Cell 4 summary\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"  Mean Squared Error (MSE): {mse_rf:.4f}\")\n",
        "print(f\"  R-squared (R2): {r2_rf:.4f}\")\n",
        "\n",
        "print(\"\\nModel evaluation complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S83LKw8Xmiot",
        "outputId": "a739b602-a8f3-475e-c5df-1e68f3543208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step: Evaluating Model Performance ---\n",
            "\n",
            "Evaluating Linear Regression Model:\n",
            "  Mean Squared Error (MSE): 1.3688\n",
            "  R-squared (R2): 0.4023\n",
            "\n",
            "Evaluating Random Forest Regressor Model:\n",
            "  Mean Squared Error (MSE): 0.0881\n",
            "  R-squared (R2): 0.9615\n",
            "\n",
            "Model evaluation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\n--- Step: Interpret Model Results and Analyze Influential Features ---\")\n",
        "\n",
        "print(\"\\n### 1. Model Performance Summary (Without Rating Color/Text) ###\")\n",
        "print(f\"Linear Regression:\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse_lr:.4f}\")\n",
        "print(f\"  R-squared (R2): {r2_lr:.4f}\")\n",
        "print(f\"\\nRandom Forest Regressor:\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse_rf:.4f}\")\n",
        "print(f\"  R-squared (R2): {r2_rf:.4f}\")\n",
        "\n",
        "print(\"\\n--- Interpretation ---\")\n",
        "print(\"With 'Rating color' and 'Rating text' removed, the R-squared values are now more realistic for predicting ratings based on independent restaurant attributes.\")\n",
        "print(\"The Random Forest Regressor (R2: {:.4f}) still significantly outperforms the Linear Regression model (R2: {:.4f}). This reinforces that non-linear relationships are crucial for accurately predicting restaurant ratings from these features.\".format(r2_rf, r2_lr))\n",
        "print(\"The lower MSE for Random Forest also confirms its superior predictive accuracy on unseen data in this more challenging scenario.\")\n",
        "\n",
        "\n",
        "print(\"\\n### 2. Feature Importance Analysis (Without Rating Color/Text) ###\")\n",
        "\n",
        "# --- Linear Regression Feature Importance (Coefficients) ---\n",
        "print(\"\\n--- Linear Regression: Most Influential Features (Coefficients) ---\")\n",
        "lr_coefficients = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': linear_reg_model.coef_\n",
        "})\n",
        "lr_coefficients['Abs_Coefficient'] = np.abs(lr_coefficients['Coefficient'])\n",
        "lr_coefficients = lr_coefficients.sort_values(by='Abs_Coefficient', ascending=False).drop(columns='Abs_Coefficient')\n",
        "\n",
        "print(\"Top 10 Most Influential Features for Linear Regression:\")\n",
        "print(lr_coefficients.head(10).to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "print(\"\\nInterpretation: For Linear Regression, a positive coefficient means an increase in that feature leads to an increase in rating, and vice-versa for negative coefficients. The magnitude indicates strength of influence.\")\n",
        "\n",
        "\n",
        "# --- Random Forest Regressor Feature Importance ---\n",
        "print(\"\\n--- Random Forest Regressor: Most Influential Features ---\")\n",
        "rf_importances = random_forest_model.feature_importances_\n",
        "feature_importances_rf = pd.Series(rf_importances, index=X.columns)\n",
        "feature_importances_rf = feature_importances_rf.sort_values(ascending=False)\n",
        "\n",
        "print(\"Top 10 Most Influential Features for Random Forest Regressor:\")\n",
        "print(feature_importances_rf.head(10).to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "print(\"\\nInterpretation: For Random Forest, feature importance indicates how much each feature contributed to reducing impurity (e.g., variance) across all trees. Higher values mean greater influence.\")\n",
        "\n",
        "print(\"\\n--- Overall Conclusion ---\")\n",
        "print(\"Now that 'Rating color' and 'Rating text' have been excluded, the feature importance analysis reveals the true independent drivers of restaurant ratings.\")\n",
        "print(\"The Random Forest Regressor remains the better model, and we can now see which restaurant attributes (beyond the rating itself) are most predictive of the aggregate rating.\")\n",
        "\n",
        "\n",
        "# --- 3. Demonstrate Prediction for a New Restaurant ---\n",
        "print(\"\\n--- Step: Demonstrating Prediction for a New Restaurant ---\")\n",
        "\n",
        "def preprocess_and_predict(new_restaurant_data_dict, model, scaler_obj, X_train_cols, num_cols_to_scale, ohe_cat_cols, bin_cols, all_cuisines_list):\n",
        "    \"\"\"\n",
        "    Preprocesses a single new restaurant data dictionary and makes a prediction.\n",
        "\n",
        "    Args:\n",
        "        new_restaurant_data_dict (dict): Dictionary containing the new restaurant's features.\n",
        "        model: The trained scikit-learn regression model.\n",
        "        scaler_obj: The fitted StandardScaler object from training.\n",
        "        X_train_cols (pd.Index): The columns of the X_train DataFrame.\n",
        "        num_cols_to_scale (list): List of numerical columns that were scaled.\n",
        "        ohe_cat_cols (list): List of original categorical columns that were one-hot encoded.\n",
        "        bin_cols (list): List of original binary columns that were converted to 0/1.\n",
        "        all_cuisines_list (list): List of all unique cuisines encountered during training.\n",
        "\n",
        "    Returns:\n",
        "        float: The predicted aggregate rating.\n",
        "    \"\"\"\n",
        "    # Convert to DataFrame\n",
        "    new_df = pd.DataFrame([new_restaurant_data_dict])\n",
        "\n",
        "    # 1. Convert binary 'Yes'/'No' columns to 1/0\n",
        "    for col in bin_cols:\n",
        "        if col in new_df.columns:\n",
        "            new_df[col] = new_df[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "        else:\n",
        "            new_df[col] = 0 # Assume 'No' if column is missing\n",
        "\n",
        "    # 2. Drop high cardinality and redundant columns (same as training)\n",
        "    local_columns_to_drop = [\n",
        "        'Restaurant Name', 'Address', 'Locality', 'Locality Verbose',\n",
        "        'Switch to order menu', 'Restaurant ID', 'Rating color', 'Rating text'\n",
        "    ]\n",
        "    new_df.drop(columns=[col for col in local_columns_to_drop if col in new_df.columns], inplace=True, errors='ignore')\n",
        "\n",
        "\n",
        "    # 3. Handle 'Cuisines' column with multi-label one-hot encoding for new data\n",
        "    cuisine_data = {cuisine: 0 for cuisine in all_cuisines_list}\n",
        "    if 'Cuisines' in new_df.columns and pd.notna(new_df['Cuisines'].iloc[0]):\n",
        "        current_cuisines = [c.strip() for c in new_df['Cuisines'].iloc[0].split(',') if c.strip()] # Handle empty strings\n",
        "        for cuisine in current_cuisines:\n",
        "            if cuisine in cuisine_data:\n",
        "                cuisine_data[cuisine] = 1\n",
        "    new_cuisine_df = pd.DataFrame([cuisine_data])\n",
        "\n",
        "    if 'Cuisines' in new_df.columns:\n",
        "        new_df.drop(columns=['Cuisines'], inplace=True)\n",
        "\n",
        "    # 4. One-Hot Encode other nominal categorical columns\n",
        "    new_df_encoded = pd.get_dummies(new_df, columns=ohe_cat_cols, drop_first=True)\n",
        "\n",
        "    # Concatenate the cuisine dummies\n",
        "    new_df_final = pd.concat([new_df_encoded, new_cuisine_df], axis=1)\n",
        "\n",
        "    # --- FIX FOR FRAGMENTATION WARNING: Align columns efficiently ---\n",
        "    # Reindex the new DataFrame to match the columns of X_train\n",
        "    # This will add missing columns (from X_train) as NaN and fill with 0\n",
        "    # And drop extra columns (if any, though unlikely if input is controlled)\n",
        "    new_processed_data = new_df_final.reindex(columns=X_train_cols, fill_value=0)\n",
        "\n",
        "    # 5. Feature Scaling for numerical columns\n",
        "    new_processed_data[num_cols_to_scale] = scaler_obj.transform(new_processed_data[num_cols_to_scale])\n",
        "\n",
        "    # Make the prediction\n",
        "    predicted_rating = model.predict(new_processed_data)\n",
        "\n",
        "    return predicted_rating[0]\n",
        "\n",
        "# Example new restaurant data\n",
        "example_restaurant_data = {\n",
        "    'Restaurant Name': 'The Cozy Corner Cafe',\n",
        "    'Country Code': 1, # India\n",
        "    'City': 'New Delhi',\n",
        "    'Longitude': 77.22,\n",
        "    'Latitude': 28.63,\n",
        "    'Cuisines': 'Cafe, Desserts, Italian',\n",
        "    'Average Cost for two': 700,\n",
        "    'Currency': 'Indian Rupees(Rs.)',\n",
        "    'Has Table booking': 'Yes',\n",
        "    'Has Online delivery': 'No',\n",
        "    'Is delivering now': 'No',\n",
        "    'Price range': 2,\n",
        "    'Votes': 150,\n",
        "}\n",
        "\n",
        "predicted_rating_example = preprocess_and_predict(\n",
        "    example_restaurant_data,\n",
        "    random_forest_model,\n",
        "    scaler,\n",
        "    X_train.columns,\n",
        "    numerical_cols_to_scale,\n",
        "    original_categorical_cols_for_ohe,\n",
        "    original_binary_cols_for_new_data,\n",
        "    original_all_cuisines\n",
        ")\n",
        "\n",
        "print(f\"\\nPredicted Aggregate Rating for 'The Cozy Corner Cafe': {predicted_rating_example:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vD8IATWmryH",
        "outputId": "e1797ad8-73fd-4d17-9c5a-136b55dd3d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step: Interpret Model Results and Analyze Influential Features ---\n",
            "\n",
            "### 1. Model Performance Summary (Without Rating Color/Text) ###\n",
            "Linear Regression:\n",
            "  Mean Squared Error (MSE): 1.3688\n",
            "  R-squared (R2): 0.4023\n",
            "\n",
            "Random Forest Regressor:\n",
            "  Mean Squared Error (MSE): 0.0881\n",
            "  R-squared (R2): 0.9615\n",
            "\n",
            "--- Interpretation ---\n",
            "With 'Rating color' and 'Rating text' removed, the R-squared values are now more realistic for predicting ratings based on independent restaurant attributes.\n",
            "The Random Forest Regressor (R2: 0.9615) still significantly outperforms the Linear Regression model (R2: 0.4023). This reinforces that non-linear relationships are crucial for accurately predicting restaurant ratings from these features.\n",
            "The lower MSE for Random Forest also confirms its superior predictive accuracy on unseen data in this more challenging scenario.\n",
            "\n",
            "### 2. Feature Importance Analysis (Without Rating Color/Text) ###\n",
            "\n",
            "--- Linear Regression: Most Influential Features (Coefficients) ---\n",
            "Top 10 Most Influential Features for Linear Regression:\n",
            "| Feature         | Coefficient   |\n",
            "|:----------------|:--------------|\n",
            "| Mineira         | -3.15044      |\n",
            "| Country Code_14 | 2.41823       |\n",
            "| Moroccan        | -1.88616      |\n",
            "| City_Mc Millan  | -1.58307      |\n",
            "| City_Beechworth | 1.56684       |\n",
            "| City_Montville  | -1.54662      |\n",
            "| City_Cochrane   | -1.53441      |\n",
            "| City_Noida      | -1.51743      |\n",
            "| Armenian        | -1.50149      |\n",
            "| City_Faridabad  | -1.49023      |\n",
            "\n",
            "Interpretation: For Linear Regression, a positive coefficient means an increase in that feature leads to an increase in rating, and vice-versa for negative coefficients. The magnitude indicates strength of influence.\n",
            "\n",
            "--- Random Forest Regressor: Most Influential Features ---\n",
            "Top 10 Most Influential Features for Random Forest Regressor:\n",
            "|                             | 0           |\n",
            "|:----------------------------|:------------|\n",
            "| Votes                       | 0.946781    |\n",
            "| Longitude                   | 0.0146277   |\n",
            "| Latitude                    | 0.0105288   |\n",
            "| Average Cost for two        | 0.00518176  |\n",
            "| Currency_Indian Rupees(Rs.) | 0.00293671  |\n",
            "| Chinese                     | 0.00181437  |\n",
            "| North Indian                | 0.00123758  |\n",
            "| Pizza                       | 0.00103235  |\n",
            "| Continental                 | 0.000985081 |\n",
            "| Has Online delivery         | 0.000978832 |\n",
            "\n",
            "Interpretation: For Random Forest, feature importance indicates how much each feature contributed to reducing impurity (e.g., variance) across all trees. Higher values mean greater influence.\n",
            "\n",
            "--- Overall Conclusion ---\n",
            "Now that 'Rating color' and 'Rating text' have been excluded, the feature importance analysis reveals the true independent drivers of restaurant ratings.\n",
            "The Random Forest Regressor remains the better model, and we can now see which restaurant attributes (beyond the rating itself) are most predictive of the aggregate rating.\n",
            "\n",
            "--- Step: Demonstrating Prediction for a New Restaurant ---\n",
            "\n",
            "Predicted Aggregate Rating for 'The Cozy Corner Cafe': 4.06\n"
          ]
        }
      ]
    }
  ]
}