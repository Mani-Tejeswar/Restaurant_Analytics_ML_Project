{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KReHFfTOUj7z",
        "outputId": "886e4d00-61f9-4172-92ab-23d01a9ce55d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- CELL 1: Data Preprocessing for Cuisine Classification ---\n",
            "--- Step 1: Loading the Dataset ---\n",
            "Dataset loaded successfully!\n",
            "Initial dataset shape: (9551, 21)\n",
            "Initial 5 rows:\n",
            "| Restaurant ID   | Restaurant Name        | Country Code   | City             | Address                                                                 | Locality                                   | Locality Verbose                                             | Longitude   | Latitude   | Cuisines                         | Average Cost for two   | Currency         | Has Table booking   | Has Online delivery   | Is delivering now   | Switch to order menu   | Price range   | Aggregate rating   | Rating color   | Rating text   | Votes   |\n",
            "|:----------------|:-----------------------|:---------------|:-----------------|:------------------------------------------------------------------------|:-------------------------------------------|:-------------------------------------------------------------|:------------|:-----------|:---------------------------------|:-----------------------|:-----------------|:--------------------|:----------------------|:--------------------|:-----------------------|:--------------|:-------------------|:---------------|:--------------|:--------|\n",
            "| 6317637         | Le Petit Souffle       | 162            | Makati City      | Third Floor, Century City Mall, Kalayaan Avenue, Poblacion, Makati City | Century City Mall, Poblacion, Makati City  | Century City Mall, Poblacion, Makati City, Makati City       | 121.028     | 14.5654    | French, Japanese, Desserts       | 1100                   | Botswana Pula(P) | Yes                 | No                    | No                  | No                     | 3             | 4.8                | Dark Green     | Excellent     | 314     |\n",
            "| 6304287         | Izakaya Kikufuji       | 162            | Makati City      | Little Tokyo, 2277 Chino Roces Avenue, Legaspi Village, Makati City     | Little Tokyo, Legaspi Village, Makati City | Little Tokyo, Legaspi Village, Makati City, Makati City      | 121.014     | 14.5537    | Japanese                         | 1200                   | Botswana Pula(P) | Yes                 | No                    | No                  | No                     | 3             | 4.5                | Dark Green     | Excellent     | 591     |\n",
            "| 6300002         | Heat - Edsa Shangri-La | 162            | Mandaluyong City | Edsa Shangri-La, 1 Garden Way, Ortigas, Mandaluyong City                | Edsa Shangri-La, Ortigas, Mandaluyong City | Edsa Shangri-La, Ortigas, Mandaluyong City, Mandaluyong City | 121.057     | 14.5814    | Seafood, Asian, Filipino, Indian | 4000                   | Botswana Pula(P) | Yes                 | No                    | No                  | No                     | 4             | 4.4                | Green          | Very Good     | 270     |\n",
            "| 6318506         | Ooma                   | 162            | Mandaluyong City | Third Floor, Mega Fashion Hall, SM Megamall, Ortigas, Mandaluyong City  | SM Megamall, Ortigas, Mandaluyong City     | SM Megamall, Ortigas, Mandaluyong City, Mandaluyong City     | 121.056     | 14.5853    | Japanese, Sushi                  | 1500                   | Botswana Pula(P) | No                  | No                    | No                  | No                     | 4             | 4.9                | Dark Green     | Excellent     | 365     |\n",
            "| 6314302         | Sambo Kojin            | 162            | Mandaluyong City | Third Floor, Mega Atrium, SM Megamall, Ortigas, Mandaluyong City        | SM Megamall, Ortigas, Mandaluyong City     | SM Megamall, Ortigas, Mandaluyong City, Mandaluyong City     | 121.058     | 14.5845    | Japanese, Korean                 | 1500                   | Botswana Pula(P) | Yes                 | No                    | No                  | No                     | 4             | 4.8                | Dark Green     | Excellent     | 229     |\n",
            "\n",
            "--- Step 2: Handling Missing Values ---\n",
            "Missing values before handling:\n",
            "|          | 0   |\n",
            "|:---------|:----|\n",
            "| Cuisines | 9   |\n",
            "Dataset shape after dropping rows with missing 'Cuisines': (9542, 21)\n",
            "Missing values after handling:\n",
            "| 0   |\n",
            "|-----|\n",
            "\n",
            "--- Step 3: Encoding Categorical Variables ---\n",
            "Binary 'Yes'/'No' columns converted to 1/0.\n",
            "| Has Table booking   | Has Online delivery   | Is delivering now   | Switch to order menu   |\n",
            "|:--------------------|:----------------------|:--------------------|:-----------------------|\n",
            "| 1                   | 0                     | 0                   | 0                      |\n",
            "| 1                   | 0                     | 0                   | 0                      |\n",
            "| 1                   | 0                     | 0                   | 0                      |\n",
            "| 0                   | 0                     | 0                   | 0                      |\n",
            "| 1                   | 0                     | 0                   | 0                      |\n",
            "Dropped high cardinality/redundant columns. Current shape: (9542, 14)\n",
            "Nominal categorical features one-hot encoded. Current shape: (9542, 183)\n",
            "\n",
            "--- Step 4: Preparing Target Variable (Cuisines) ---\n",
            "Shape of multi-label target (y): (9542, 145)\n",
            "Number of unique cuisines: 145\n",
            "First 5 rows of multi-label target (y):\n",
            "| Afghani   | African   | American   | Andhra   | Arabian   | Argentine   | Armenian   | Asian   | Asian Fusion   | Assamese   | Australian   | Awadhi   | BBQ   | Bakery   | Bar Food   | Belgian   | Bengali   | Beverages   | Bihari   | Biryani   | Brazilian   | Breakfast   | British   | Bubble Tea   | Burger   | Burmese   | B�_rek   | Cafe   | Cajun   | Canadian   | Cantonese   | Caribbean   | Charcoal Grill   | Chettinad   | Chinese   | Coffee and Tea   | Contemporary   | Continental   | Cuban   | Cuisine Varies   | Curry   | Deli   | Desserts   | Dim Sum   | Diner   | Drinks Only   | Durban   | D�_ner   | European   | Fast Food   | Filipino   | Finger Food   | Fish and Chips   | French   | Fusion   | German   | Goan   | Gourmet Fast Food   | Greek   | Grill   | Gujarati   | Hawaiian   | Healthy Food   | Hyderabadi   | Ice Cream   | Indian   | Indonesian   | International   | Iranian   | Irish   | Italian   | Izgara   | Japanese   | Juices   | Kashmiri   | Kebab   | Kerala   | Kiwi   | Korean   | Latin American   | Lebanese   | Lucknowi   | Maharashtrian   | Malay   | Malaysian   | Malwani   | Mangalorean   | Mediterranean   | Mexican   | Middle Eastern   | Mineira   | Mithai   | Modern Australian   | Modern Indian   | Moroccan   | Mughlai   | Naga   | Nepalese   | New American   | North Eastern   | North Indian   | Oriya   | Pakistani   | Parsi   | Patisserie   | Peranakan   | Persian   | Peruvian   | Pizza   | Portuguese   | Pub Food   | Rajasthani   | Ramen   | Raw Meats   | Restaurant Cafe   | Salad   | Sandwich   | Scottish   | Seafood   | Singaporean   | Soul Food   | South African   | South American   | South Indian   | Southern   | Southwestern   | Spanish   | Sri Lankan   | Steak   | Street Food   | Sunda   | Sushi   | Taiwanese   | Tapas   | Tea   | Teriyaki   | Tex-Mex   | Thai   | Tibetan   | Turkish   | Turkish Pizza   | Vegetarian   | Vietnamese   | Western   | World Cuisine   |\n",
            "|:----------|:----------|:-----------|:---------|:----------|:------------|:-----------|:--------|:---------------|:-----------|:-------------|:---------|:------|:---------|:-----------|:----------|:----------|:------------|:---------|:----------|:------------|:------------|:----------|:-------------|:---------|:----------|:---------|:-------|:--------|:-----------|:------------|:------------|:-----------------|:------------|:----------|:-----------------|:---------------|:--------------|:--------|:-----------------|:--------|:-------|:-----------|:----------|:--------|:--------------|:---------|:---------|:-----------|:------------|:-----------|:--------------|:-----------------|:---------|:---------|:---------|:-------|:--------------------|:--------|:--------|:-----------|:-----------|:---------------|:-------------|:------------|:---------|:-------------|:----------------|:----------|:--------|:----------|:---------|:-----------|:---------|:-----------|:--------|:---------|:-------|:---------|:-----------------|:-----------|:-----------|:----------------|:--------|:------------|:----------|:--------------|:----------------|:----------|:-----------------|:----------|:---------|:--------------------|:----------------|:-----------|:----------|:-------|:-----------|:---------------|:----------------|:---------------|:--------|:------------|:--------|:-------------|:------------|:----------|:-----------|:--------|:-------------|:-----------|:-------------|:--------|:------------|:------------------|:--------|:-----------|:-----------|:----------|:--------------|:------------|:----------------|:-----------------|:---------------|:-----------|:---------------|:----------|:-------------|:--------|:--------------|:--------|:--------|:------------|:--------|:------|:-----------|:----------|:-------|:----------|:----------|:----------------|:-------------|:-------------|:----------|:----------------|\n",
            "| 0         | 0         | 0          | 0        | 0         | 0           | 0          | 0       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 1          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 0          | 0             | 0                | 1        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 0        | 0            | 0               | 0         | 0       | 0         | 0        | 1          | 0        | 0          | 0       | 0        | 0      | 0        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 0         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 0       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "| 0         | 0         | 0          | 0        | 0         | 0           | 0          | 0       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 0          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 0          | 0             | 0                | 0        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 0        | 0            | 0               | 0         | 0       | 0         | 0        | 1          | 0        | 0          | 0       | 0        | 0      | 0        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 0         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 0       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "| 0         | 0         | 0          | 0        | 0         | 0           | 0          | 1       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 0          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 1          | 0             | 0                | 0        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 1        | 0            | 0               | 0         | 0       | 0         | 0        | 0          | 0        | 0          | 0       | 0        | 0      | 0        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 1         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 0       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "| 0         | 0         | 0          | 0        | 0         | 0           | 0          | 0       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 0          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 0          | 0             | 0                | 0        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 0        | 0            | 0               | 0         | 0       | 0         | 0        | 1          | 0        | 0          | 0       | 0        | 0      | 0        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 0         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 1       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "| 0         | 0         | 0          | 0        | 0         | 0           | 0          | 0       | 0              | 0          | 0            | 0        | 0     | 0        | 0          | 0         | 0         | 0           | 0        | 0         | 0           | 0           | 0         | 0            | 0        | 0         | 0        | 0      | 0       | 0          | 0           | 0           | 0                | 0           | 0         | 0                | 0              | 0             | 0       | 0                | 0       | 0      | 0          | 0         | 0       | 0             | 0        | 0        | 0          | 0           | 0          | 0             | 0                | 0        | 0        | 0        | 0      | 0                   | 0       | 0       | 0          | 0          | 0              | 0            | 0           | 0        | 0            | 0               | 0         | 0       | 0         | 0        | 1          | 0        | 0          | 0       | 0        | 0      | 1        | 0                | 0          | 0          | 0               | 0       | 0           | 0         | 0             | 0               | 0         | 0                | 0         | 0        | 0                   | 0               | 0          | 0         | 0      | 0          | 0              | 0               | 0              | 0       | 0           | 0       | 0            | 0           | 0         | 0          | 0       | 0            | 0          | 0            | 0       | 0           | 0                 | 0       | 0          | 0          | 0         | 0             | 0           | 0               | 0                | 0              | 0          | 0              | 0         | 0            | 0       | 0             | 0       | 0       | 0           | 0       | 0     | 0          | 0         | 0      | 0         | 0         | 0               | 0            | 0            | 0         | 0               |\n",
            "\n",
            "--- Step 5: Separating Features (X) ---\n",
            "Shape of features (X): (9542, 182)\n",
            "First 5 rows of X (before scaling numerical features):\n",
            "| Longitude   | Latitude   | Average Cost for two   | Has Table booking   | Has Online delivery   | Is delivering now   | Price range   | Votes   | Country Code_14   | Country Code_30   | Country Code_37   | Country Code_94   | Country Code_148   | Country Code_162   | Country Code_166   | Country Code_184   | Country Code_189   | Country Code_191   | Country Code_208   | Country Code_214   | Country Code_215   | Country Code_216   | City_Agra   | City_Ahmedabad   | City_Albany   | City_Allahabad   | City_Amritsar   | City_Ankara   | City_Armidale   | City_Athens   | City_Auckland   | City_Augusta   | City_Aurangabad   | City_Balingup   | City_Bandung   | City_Bangalore   | City_Beechworth   | City_Bhopal   | City_Bhubaneshwar   | City_Birmingham   | City_Bogor   | City_Boise   | City_Bras�_lia   | City_Cape Town   | City_Cedar Rapids/Iowa City   | City_Chandigarh   | City_Chatham-Kent   | City_Chennai   | City_Clatskanie   | City_Cochrane   | City_Coimbatore   | City_Colombo   | City_Columbus   | City_Consort   | City_Dalton   | City_Davenport   | City_Dehradun   | City_Des Moines   | City_Dicky Beach   | City_Doha   | City_Dubai   | City_Dubuque   | City_East Ballina   | City_Edinburgh   | City_Faridabad   | City_Fernley   | City_Flaxton   | City_Forrest   | City_Gainesville   | City_Ghaziabad   | City_Goa   | City_Gurgaon   | City_Guwahati   | City_Hepburn Springs   | City_Huskisson   | City_Hyderabad   | City_Indore   | City_Inner City   | City_Inverloch   | City_Jaipur   | City_Jakarta   | City_Johannesburg   | City_Kanpur   | City_Kochi   | City_Kolkata   | City_Lakes Entrance   | City_Lakeview   | City_Lincoln   | City_London   | City_Lorn   | City_Lucknow   | City_Ludhiana   | City_Macedon   | City_Macon   | City_Makati City   | City_Manchester   | City_Mandaluyong City   | City_Mangalore   | City_Mayfield   | City_Mc Millan   | City_Middleton Beach   | City_Mohali   | City_Monroe   | City_Montville   | City_Mumbai   | City_Mysore   | City_Nagpur   | City_Nashik   | City_New Delhi   | City_Noida   | City_Ojo Caliente   | City_Orlando   | City_Palm Cove   | City_Panchkula   | City_Pasay City   | City_Pasig City   | City_Patna   | City_Paynesville   | City_Penola   | City_Pensacola   | City_Phillip Island   | City_Pocatello   | City_Potrero   | City_Pretoria   | City_Princeton   | City_Puducherry   | City_Pune   | City_Quezon City   | City_Ranchi   | City_Randburg   | City_Rest of Hawaii   | City_Rio de Janeiro   | City_San Juan City   | City_Sandton   | City_Santa Rosa   | City_Savannah   | City_Secunderabad   | City_Sharjah   | City_Singapore   | City_Sioux City   | City_Surat   | City_S��o Paulo   | City_Tagaytay City   | City_Taguig City   | City_Tampa Bay   | City_Tangerang   | City_Tanunda   | City_Trentham East   | City_Vadodara   | City_Valdosta   | City_Varanasi   | City_Vernonia   | City_Victor Harbor   | City_Vineland Station   | City_Vizag   | City_Waterloo   | City_Weirton   | City_Wellington City   | City_Winchester Bay   | City_Yorkton   | City_��stanbul   | Currency_Brazilian Real(R$)   | Currency_Dollar($)   | Currency_Emirati Diram(AED)   | Currency_Indian Rupees(Rs.)   | Currency_Indonesian Rupiah(IDR)   | Currency_NewZealand($)   | Currency_Pounds(��)   | Currency_Qatari Rial(QR)   | Currency_Rand(R)   | Currency_Sri Lankan Rupee(LKR)   | Currency_Turkish Lira(TL)   | Rating color_Green   | Rating color_Orange   | Rating color_Red   | Rating color_White   | Rating color_Yellow   | Rating text_Excellent   | Rating text_Good   | Rating text_Not rated   | Rating text_Poor   | Rating text_Very Good   |\n",
            "|:------------|:-----------|:-----------------------|:--------------------|:----------------------|:--------------------|:--------------|:--------|:------------------|:------------------|:------------------|:------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:------------|:-----------------|:--------------|:-----------------|:----------------|:--------------|:----------------|:--------------|:----------------|:---------------|:------------------|:----------------|:---------------|:-----------------|:------------------|:--------------|:--------------------|:------------------|:-------------|:-------------|:-----------------|:-----------------|:------------------------------|:------------------|:--------------------|:---------------|:------------------|:----------------|:------------------|:---------------|:----------------|:---------------|:--------------|:-----------------|:----------------|:------------------|:-------------------|:------------|:-------------|:---------------|:--------------------|:-----------------|:-----------------|:---------------|:---------------|:---------------|:-------------------|:-----------------|:-----------|:---------------|:----------------|:-----------------------|:-----------------|:-----------------|:--------------|:------------------|:-----------------|:--------------|:---------------|:--------------------|:--------------|:-------------|:---------------|:----------------------|:----------------|:---------------|:--------------|:------------|:---------------|:----------------|:---------------|:-------------|:-------------------|:------------------|:------------------------|:-----------------|:----------------|:-----------------|:-----------------------|:--------------|:--------------|:-----------------|:--------------|:--------------|:--------------|:--------------|:-----------------|:-------------|:--------------------|:---------------|:-----------------|:-----------------|:------------------|:------------------|:-------------|:-------------------|:--------------|:-----------------|:----------------------|:-----------------|:---------------|:----------------|:-----------------|:------------------|:------------|:-------------------|:--------------|:----------------|:----------------------|:----------------------|:---------------------|:---------------|:------------------|:----------------|:--------------------|:---------------|:-----------------|:------------------|:-------------|:------------------|:---------------------|:-------------------|:-----------------|:-----------------|:---------------|:---------------------|:----------------|:----------------|:----------------|:----------------|:---------------------|:------------------------|:-------------|:----------------|:---------------|:-----------------------|:----------------------|:---------------|:-----------------|:------------------------------|:---------------------|:------------------------------|:------------------------------|:----------------------------------|:-------------------------|:----------------------|:---------------------------|:-------------------|:---------------------------------|:----------------------------|:---------------------|:----------------------|:-------------------|:---------------------|:----------------------|:------------------------|:-------------------|:------------------------|:-------------------|:------------------------|\n",
            "| 121.028     | 14.5654    | 1100                   | 1                   | 0                     | 0                   | 3             | 314     | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | True               | False             | False                   | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | False                | False                 | False              | False                | False                 | True                    | False              | False                   | False              | False                   |\n",
            "| 121.014     | 14.5537    | 1200                   | 1                   | 0                     | 0                   | 3             | 591     | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | True               | False             | False                   | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | False                | False                 | False              | False                | False                 | True                    | False              | False                   | False              | False                   |\n",
            "| 121.057     | 14.5814    | 4000                   | 1                   | 0                     | 0                   | 4             | 270     | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | False              | False             | True                    | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | True                 | False                 | False              | False                | False                 | False                   | False              | False                   | False              | True                    |\n",
            "| 121.056     | 14.5853    | 1500                   | 0                   | 0                     | 0                   | 4             | 365     | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | False              | False             | True                    | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | False                | False                 | False              | False                | False                 | True                    | False              | False                   | False              | False                   |\n",
            "| 121.058     | 14.5845    | 1500                   | 1                   | 0                     | 0                   | 4             | 229     | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | False              | False             | True                    | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | False                | False                 | False              | False                | False                 | True                    | False              | False                   | False              | False                   |\n",
            "\n",
            "--- Step 6: Feature Scaling ---\n",
            "Numerical features scaled using StandardScaler.\n",
            "First 5 rows of X (after scaling numerical features):\n",
            "| Longitude   | Latitude   | Average Cost for two   | Has Table booking   | Has Online delivery   | Is delivering now   | Price range   | Votes    | Country Code_14   | Country Code_30   | Country Code_37   | Country Code_94   | Country Code_148   | Country Code_162   | Country Code_166   | Country Code_184   | Country Code_189   | Country Code_191   | Country Code_208   | Country Code_214   | Country Code_215   | Country Code_216   | City_Agra   | City_Ahmedabad   | City_Albany   | City_Allahabad   | City_Amritsar   | City_Ankara   | City_Armidale   | City_Athens   | City_Auckland   | City_Augusta   | City_Aurangabad   | City_Balingup   | City_Bandung   | City_Bangalore   | City_Beechworth   | City_Bhopal   | City_Bhubaneshwar   | City_Birmingham   | City_Bogor   | City_Boise   | City_Bras�_lia   | City_Cape Town   | City_Cedar Rapids/Iowa City   | City_Chandigarh   | City_Chatham-Kent   | City_Chennai   | City_Clatskanie   | City_Cochrane   | City_Coimbatore   | City_Colombo   | City_Columbus   | City_Consort   | City_Dalton   | City_Davenport   | City_Dehradun   | City_Des Moines   | City_Dicky Beach   | City_Doha   | City_Dubai   | City_Dubuque   | City_East Ballina   | City_Edinburgh   | City_Faridabad   | City_Fernley   | City_Flaxton   | City_Forrest   | City_Gainesville   | City_Ghaziabad   | City_Goa   | City_Gurgaon   | City_Guwahati   | City_Hepburn Springs   | City_Huskisson   | City_Hyderabad   | City_Indore   | City_Inner City   | City_Inverloch   | City_Jaipur   | City_Jakarta   | City_Johannesburg   | City_Kanpur   | City_Kochi   | City_Kolkata   | City_Lakes Entrance   | City_Lakeview   | City_Lincoln   | City_London   | City_Lorn   | City_Lucknow   | City_Ludhiana   | City_Macedon   | City_Macon   | City_Makati City   | City_Manchester   | City_Mandaluyong City   | City_Mangalore   | City_Mayfield   | City_Mc Millan   | City_Middleton Beach   | City_Mohali   | City_Monroe   | City_Montville   | City_Mumbai   | City_Mysore   | City_Nagpur   | City_Nashik   | City_New Delhi   | City_Noida   | City_Ojo Caliente   | City_Orlando   | City_Palm Cove   | City_Panchkula   | City_Pasay City   | City_Pasig City   | City_Patna   | City_Paynesville   | City_Penola   | City_Pensacola   | City_Phillip Island   | City_Pocatello   | City_Potrero   | City_Pretoria   | City_Princeton   | City_Puducherry   | City_Pune   | City_Quezon City   | City_Ranchi   | City_Randburg   | City_Rest of Hawaii   | City_Rio de Janeiro   | City_San Juan City   | City_Sandton   | City_Santa Rosa   | City_Savannah   | City_Secunderabad   | City_Sharjah   | City_Singapore   | City_Sioux City   | City_Surat   | City_S��o Paulo   | City_Tagaytay City   | City_Taguig City   | City_Tampa Bay   | City_Tangerang   | City_Tanunda   | City_Trentham East   | City_Vadodara   | City_Valdosta   | City_Varanasi   | City_Vernonia   | City_Victor Harbor   | City_Vineland Station   | City_Vizag   | City_Waterloo   | City_Weirton   | City_Wellington City   | City_Winchester Bay   | City_Yorkton   | City_��stanbul   | Currency_Brazilian Real(R$)   | Currency_Dollar($)   | Currency_Emirati Diram(AED)   | Currency_Indian Rupees(Rs.)   | Currency_Indonesian Rupiah(IDR)   | Currency_NewZealand($)   | Currency_Pounds(��)   | Currency_Qatari Rial(QR)   | Currency_Rand(R)   | Currency_Sri Lankan Rupee(LKR)   | Currency_Turkish Lira(TL)   | Rating color_Green   | Rating color_Orange   | Rating color_Red   | Rating color_White   | Rating color_Yellow   | Rating text_Excellent   | Rating text_Good   | Rating text_Not rated   | Rating text_Poor   | Rating text_Very Good   |\n",
            "|:------------|:-----------|:-----------------------|:--------------------|:----------------------|:--------------------|:--------------|:---------|:------------------|:------------------|:------------------|:------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:-------------------|:------------|:-----------------|:--------------|:-----------------|:----------------|:--------------|:----------------|:--------------|:----------------|:---------------|:------------------|:----------------|:---------------|:-----------------|:------------------|:--------------|:--------------------|:------------------|:-------------|:-------------|:-----------------|:-----------------|:------------------------------|:------------------|:--------------------|:---------------|:------------------|:----------------|:------------------|:---------------|:----------------|:---------------|:--------------|:-----------------|:----------------|:------------------|:-------------------|:------------|:-------------|:---------------|:--------------------|:-----------------|:-----------------|:---------------|:---------------|:---------------|:-------------------|:-----------------|:-----------|:---------------|:----------------|:-----------------------|:-----------------|:-----------------|:--------------|:------------------|:-----------------|:--------------|:---------------|:--------------------|:--------------|:-------------|:---------------|:----------------------|:----------------|:---------------|:--------------|:------------|:---------------|:----------------|:---------------|:-------------|:-------------------|:------------------|:------------------------|:-----------------|:----------------|:-----------------|:-----------------------|:--------------|:--------------|:-----------------|:--------------|:--------------|:--------------|:--------------|:-----------------|:-------------|:--------------------|:---------------|:-----------------|:-----------------|:------------------|:------------------|:-------------|:-------------------|:--------------|:-----------------|:----------------------|:-----------------|:---------------|:----------------|:-----------------|:------------------|:------------|:-------------------|:--------------|:----------------|:----------------------|:----------------------|:---------------------|:---------------|:------------------|:----------------|:--------------------|:---------------|:-----------------|:------------------|:-------------|:------------------|:---------------------|:-------------------|:-----------------|:-----------------|:---------------|:---------------------|:----------------|:----------------|:----------------|:----------------|:---------------------|:------------------------|:-------------|:----------------|:---------------|:-----------------------|:----------------------|:---------------|:-----------------|:------------------------------|:---------------------|:------------------------------|:------------------------------|:----------------------------------|:-------------------------|:----------------------|:---------------------------|:-------------------|:---------------------------------|:----------------------------|:---------------------|:----------------------|:-------------------|:---------------------|:----------------------|:------------------------|:-------------------|:------------------------|:-------------------|:------------------------|\n",
            "| 1.37764     | -1.02485   | -0.00622066            | 1                   | 0                     | 0                   | 1.31973       | 0.365493 | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | True               | False             | False                   | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | False                | False                 | False              | False                | False                 | True                    | False              | False                   | False              | False                   |\n",
            "| 1.37732     | -1.02591   | -2.02219e-05           | 1                   | 0                     | 0                   | 1.31973       | 1.00941  | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | True               | False             | False                   | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | False                | False                 | False              | False                | False                 | True                    | False              | False                   | False              | False                   |\n",
            "| 1.37835     | -1.0234    | 0.173592               | 1                   | 0                     | 0                   | 2.42407       | 0.26321  | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | False              | False             | True                    | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | True                 | False                 | False              | False                | False                 | False                   | False              | False                   | False              | True                    |\n",
            "| 1.37834     | -1.02304   | 0.0185811              | 0                   | 0                     | 0                   | 2.42407       | 0.484048 | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | False              | False             | True                    | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | False                | False                 | False              | False                | False                 | True                    | False              | False                   | False              | False                   |\n",
            "| 1.37837     | -1.02312   | 0.0185811              | 1                   | 0                     | 0                   | 2.42407       | 0.167901 | False             | False             | False             | False             | False              | True               | False              | False              | False              | False              | False              | False              | False              | False              | False       | False            | False         | False            | False           | False         | False           | False         | False           | False          | False             | False           | False          | False            | False             | False         | False               | False             | False        | False        | False            | False            | False                         | False             | False               | False          | False             | False           | False             | False          | False           | False          | False         | False            | False           | False             | False              | False       | False        | False          | False               | False            | False            | False          | False          | False          | False              | False            | False      | False          | False           | False                  | False            | False            | False         | False             | False            | False         | False          | False               | False         | False        | False          | False                 | False           | False          | False         | False       | False          | False           | False          | False        | False              | False             | True                    | False            | False           | False            | False                  | False         | False         | False            | False         | False         | False         | False         | False            | False        | False               | False          | False            | False            | False             | False             | False        | False              | False         | False            | False                 | False            | False          | False           | False            | False             | False       | False              | False         | False           | False                 | False                 | False                | False          | False             | False           | False               | False          | False            | False             | False        | False             | False                | False              | False            | False            | False          | False                | False           | False           | False           | False           | False                | False                   | False        | False           | False          | False                  | False                 | False          | False            | False                         | False                | False                         | False                         | False                             | False                    | False                 | False                      | False              | False                            | False                       | False                | False                 | False              | False                | False                 | True                    | False              | False                   | False              | False                   |\n",
            "\n",
            "--- Step 7: Splitting Data into Training and Testing Sets ---\n",
            "X_train shape: (7633, 182)\n",
            "X_test shape: (1909, 182)\n",
            "y_train shape: (7633, 145)\n",
            "y_test shape: (1909, 145)\n",
            "\n",
            "Preprocessing for Cuisine Classification complete! Data is ready for model training.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# --- Global variables for consistent preprocessing ---\n",
        "global scaler_cuisine_classifier, mlb_cuisines, X_cuisine_train_cols\n",
        "global original_categorical_cols_cuisine, original_binary_cols_cuisine\n",
        "\n",
        "print(\"--- CELL 1: Data Preprocessing for Cuisine Classification ---\")\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "print(\"--- Step 1: Loading the Dataset ---\")\n",
        "file_path = 'Dataset .csv'\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Error: '{file_path}' not found. Please ensure the dataset file is in the same directory.\")\n",
        "    exit()\n",
        "\n",
        "df = pd.read_csv('/content/Dataset .csv')\n",
        "print(\"Dataset loaded successfully!\")\n",
        "\n",
        "print(f\"Initial dataset shape: {df.shape}\")\n",
        "print(\"Initial 5 rows:\")\n",
        "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# --- 2. Handle Missing Values ---\n",
        "print(\"\\n--- Step 2: Handling Missing Values ---\")\n",
        "print(\"Missing values before handling:\")\n",
        "print(df.isnull().sum()[df.isnull().sum() > 0].to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "# Drop rows with missing values in 'Cuisines' as it's our target variable\n",
        "df.dropna(subset=['Cuisines'], inplace=True)\n",
        "print(f\"Dataset shape after dropping rows with missing 'Cuisines': {df.shape}\")\n",
        "print(\"Missing values after handling:\")\n",
        "print(df.isnull().sum()[df.isnull().sum() > 0].to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# --- 3. Encode Categorical Variables ---\n",
        "print(\"\\n--- Step 3: Encoding Categorical Variables ---\")\n",
        "\n",
        "# Convert binary 'Yes'/'No' columns to 1/0\n",
        "original_binary_cols_cuisine = ['Has Table booking', 'Has Online delivery', 'Is delivering now', 'Switch to order menu']\n",
        "for col in original_binary_cols_cuisine:\n",
        "    df[col] = df[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "print(\"Binary 'Yes'/'No' columns converted to 1/0.\")\n",
        "print(df[original_binary_cols_cuisine].head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# Drop high cardinality and redundant columns (excluding 'Cuisines' as it's the target)\n",
        "columns_to_drop_for_classification = [\n",
        "    'Restaurant Name',\n",
        "    'Address',\n",
        "    'Locality',\n",
        "    'Locality Verbose',\n",
        "    'Switch to order menu', # Only 'No' values, not useful\n",
        "    'Restaurant ID',        # Identifier, not a feature\n",
        "    'Aggregate rating'      # This is the target for Task 1, but a feature here\n",
        "]\n",
        "df.drop(columns=columns_to_drop_for_classification, inplace=True)\n",
        "print(f\"Dropped high cardinality/redundant columns. Current shape: {df.shape}\")\n",
        "\n",
        "\n",
        "# One-Hot Encode other nominal categorical features\n",
        "original_categorical_cols_cuisine = ['Country Code', 'City', 'Currency', 'Rating color', 'Rating text']\n",
        "df = pd.get_dummies(df, columns=original_categorical_cols_cuisine, drop_first=True)\n",
        "print(f\"Nominal categorical features one-hot encoded. Current shape: {df.shape}\")\n",
        "\n",
        "\n",
        "# --- 4. Prepare Target Variable (Cuisines) for Multi-label Classification ---\n",
        "print(\"\\n--- Step 4: Preparing Target Variable (Cuisines) ---\")\n",
        "# Split the 'Cuisines' string into a list of individual cuisines\n",
        "df['Cuisines_List'] = df['Cuisines'].apply(lambda x: [c.strip() for c in x.split(',') if c.strip()])\n",
        "\n",
        "# Initialize MultiLabelBinarizer\n",
        "mlb_cuisines = MultiLabelBinarizer()\n",
        "\n",
        "# Fit and transform the 'Cuisines_List' to create the multi-hot encoded target variable (y)\n",
        "y = mlb_cuisines.fit_transform(df['Cuisines_List'])\n",
        "y_df = pd.DataFrame(y, columns=mlb_cuisines.classes_) # Convert to DataFrame for easier inspection\n",
        "\n",
        "print(f\"Shape of multi-label target (y): {y.shape}\")\n",
        "print(f\"Number of unique cuisines: {len(mlb_cuisines.classes_)}\")\n",
        "print(\"First 5 rows of multi-label target (y):\")\n",
        "print(y_df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# --- 5. Separate Features (X) ---\n",
        "print(\"\\n--- Step 5: Separating Features (X) ---\")\n",
        "# X will be all columns except the original 'Cuisines' and 'Cuisines_List'\n",
        "X = df.drop(columns=['Cuisines', 'Cuisines_List'])\n",
        "\n",
        "print(f\"Shape of features (X): {X.shape}\")\n",
        "print(\"First 5 rows of X (before scaling numerical features):\")\n",
        "print(X.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# --- 6. Feature Scaling ---\n",
        "print(\"\\n--- Step 6: Feature Scaling ---\")\n",
        "# Identify numerical columns to scale (excluding binary and one-hot encoded features)\n",
        "numerical_cols_to_scale = ['Longitude', 'Latitude', 'Average Cost for two', 'Price range', 'Votes']\n",
        "numerical_cols_to_scale = [col for col in numerical_cols_to_scale if col in X.columns and pd.api.types.is_numeric_dtype(X[col])]\n",
        "\n",
        "scaler_cuisine_classifier = StandardScaler()\n",
        "X[numerical_cols_to_scale] = scaler_cuisine_classifier.fit_transform(X[numerical_cols_to_scale])\n",
        "print(\"Numerical features scaled using StandardScaler.\")\n",
        "print(\"First 5 rows of X (after scaling numerical features):\")\n",
        "print(X.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# --- 7. Splitting the Data into Training and Testing Sets ---\n",
        "print(\"\\n--- Step 7: Splitting Data into Training and Testing Sets ---\")\n",
        "# Use the multi-label y for splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_cuisine_train_cols = X_train.columns # Store column names for consistent prediction\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "print(\"\\nPreprocessing for Cuisine Classification complete! Data is ready for model training.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import os\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'Dataset .csv'\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Error: '{file_path}' not found. Please ensure the dataset file is in the same directory.\")\n",
        "    exit()\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Handle Missing Values\n",
        "df.dropna(subset=['Cuisines'], inplace=True)\n",
        "\n",
        "# Convert binary 'Yes'/'No' columns to 1/0\n",
        "original_binary_cols_cuisine = ['Has Table booking', 'Has Online delivery', 'Is delivering now', 'Switch to order menu']\n",
        "for col in original_binary_cols_cuisine:\n",
        "    df[col] = df[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# Drop high cardinality and redundant columns\n",
        "columns_to_drop_for_classification = [\n",
        "    'Restaurant Name', 'Address', 'Locality', 'Locality Verbose',\n",
        "    'Switch to order menu', 'Restaurant ID', 'Aggregate rating'\n",
        "]\n",
        "df.drop(columns=columns_to_drop_for_classification, inplace=True)\n",
        "\n",
        "# One-Hot Encode other nominal categorical features\n",
        "original_categorical_cols_cuisine = ['Country Code', 'City', 'Currency', 'Rating color', 'Rating text']\n",
        "df = pd.get_dummies(df, columns=original_categorical_cols_cuisine, drop_first=True)\n",
        "\n",
        "# Prepare Target Variable (Cuisines) for Multi-label Classification\n",
        "df['Cuisines_List'] = df['Cuisines'].apply(lambda x: [c.strip() for c in x.split(',') if c.strip()])\n",
        "mlb_cuisines = MultiLabelBinarizer()\n",
        "y = mlb_cuisines.fit_transform(df['Cuisines_List'])\n",
        "\n",
        "# Separate Features (X)\n",
        "X = df.drop(columns=['Cuisines', 'Cuisines_List'])\n",
        "\n",
        "# Feature Scaling\n",
        "numerical_cols_to_scale = ['Longitude', 'Latitude', 'Average Cost for two', 'Price range', 'Votes']\n",
        "numerical_cols_to_scale = [col for col in numerical_cols_to_scale if col in X.columns and pd.api.types.is_numeric_dtype(X[col])]\n",
        "scaler_cuisine_classifier = StandardScaler()\n",
        "X[numerical_cols_to_scale] = scaler_cuisine_classifier.fit_transform(X[numerical_cols_to_scale])\n",
        "\n",
        "# Splitting the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_cuisine_train_cols = X_train.columns\n",
        "\n",
        "print(\"--- Preprocessing complete. Data ready for model training. ---\")\n",
        "\n",
        "# --- Model Selection and Training ---\n",
        "print(\"\\n--- CELL 2: Model Selection and Training (Cuisine Classification) ---\")\n",
        "\n",
        "base_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "\n",
        "print(\"\\nTraining OneVsRestClassifier with RandomForestClassifier base estimator...\")\n",
        "global cuisine_classifier_model # Make global for evaluation\n",
        "cuisine_classifier_model = OneVsRestClassifier(base_classifier)\n",
        "cuisine_classifier_model.fit(X_train, y_train)\n",
        "print(\"Cuisine Classification Model trained successfully!\")\n",
        "\n",
        "print(\"\\nModel is trained and ready for evaluation.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkSyQuUWU2n4",
        "outputId": "c54dc104-fcad-4980-dcfe-8348c962aaba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Preprocessing complete. Data ready for model training. ---\n",
            "\n",
            "--- CELL 2: Model Selection and Training (Cuisine Classification) ---\n",
            "\n",
            "Training OneVsRestClassifier with RandomForestClassifier base estimator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/multiclass.py:90: UserWarning: Label not 26 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/multiclass.py:90: UserWarning: Label not 105 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/multiclass.py:90: UserWarning: Label not 107 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuisine Classification Model trained successfully!\n",
            "\n",
            "Model is trained and ready for evaluation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import os\n",
        "import numpy as np # For thresholding predictions\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'Dataset .csv'\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Error: '{file_path}' not found. Please ensure the dataset file is in the same directory.\")\n",
        "    exit()\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Handle Missing Values\n",
        "df.dropna(subset=['Cuisines'], inplace=True)\n",
        "\n",
        "# Convert binary 'Yes'/'No' columns to 1/0\n",
        "original_binary_cols_cuisine = ['Has Table booking', 'Has Online delivery', 'Is delivering now', 'Switch to order menu']\n",
        "for col in original_binary_cols_cuisine:\n",
        "    df[col] = df[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# Drop high cardinality and redundant columns\n",
        "columns_to_drop_for_classification = [\n",
        "    'Restaurant Name', 'Address', 'Locality', 'Locality Verbose',\n",
        "    'Switch to order menu', 'Restaurant ID', 'Aggregate rating'\n",
        "]\n",
        "df.drop(columns=columns_to_drop_for_classification, inplace=True)\n",
        "\n",
        "# One-Hot Encode other nominal categorical features\n",
        "original_categorical_cols_cuisine = ['Country Code', 'City', 'Currency', 'Rating color', 'Rating text']\n",
        "df = pd.get_dummies(df, columns=original_categorical_cols_cuisine, drop_first=True)\n",
        "\n",
        "# Prepare Target Variable (Cuisines) for Multi-label Classification\n",
        "df['Cuisines_List'] = df['Cuisines'].apply(lambda x: [c.strip() for c in x.split(',') if c.strip()])\n",
        "mlb_cuisines = MultiLabelBinarizer()\n",
        "y = mlb_cuisines.fit_transform(df['Cuisines_List'])\n",
        "\n",
        "# Separate Features (X)\n",
        "X = df.drop(columns=['Cuisines', 'Cuisines_List'])\n",
        "\n",
        "# Feature Scaling\n",
        "numerical_cols_to_scale = ['Longitude', 'Latitude', 'Average Cost for two', 'Price range', 'Votes']\n",
        "numerical_cols_to_scale = [col for col in numerical_cols_to_scale if col in X.columns and pd.api.types.is_numeric_dtype(X[col])]\n",
        "scaler_cuisine_classifier = StandardScaler()\n",
        "X[numerical_cols_to_scale] = scaler_cuisine_classifier.fit_transform(X[numerical_cols_to_scale])\n",
        "\n",
        "# Splitting the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_cuisine_train_cols = X_train.columns\n",
        "\n",
        "# Model Training\n",
        "base_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "cuisine_classifier_model = OneVsRestClassifier(base_classifier)\n",
        "cuisine_classifier_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"--- Preprocessing and Model Training complete. Ready for evaluation. ---\")\n",
        "\n",
        "# --- Evaluate Model Performance ---\n",
        "print(\"\\n--- CELL 3: Evaluate Model Performance (Cuisine Classification) ---\")\n",
        "\n",
        "# Predict probabilities on the test set\n",
        "y_pred_proba = cuisine_classifier_model.predict_proba(X_test)\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold\n",
        "# A common threshold is 0.5. You can tune this if needed.\n",
        "threshold = 0.5\n",
        "y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "print(f\"\\n--- Evaluation Metrics (Threshold = {threshold}) ---\")\n",
        "\n",
        "# Calculate overall metrics (micro average is often good for multi-label, accounts for class imbalance)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision_micro = precision_score(y_test, y_pred, average='micro')\n",
        "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
        "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Micro-averaged Precision: {precision_micro:.4f}\")\n",
        "print(f\"Micro-averaged Recall: {recall_micro:.4f}\")\n",
        "print(f\"Micro-averaged F1-score: {f1_micro:.4f}\")\n",
        "\n",
        "# Detailed Classification Report (per-class metrics)\n",
        "print(\"\\n--- Detailed Classification Report (Per Cuisine) ---\")\n",
        "# Use mlb_cuisines.classes_ for target_names to get meaningful labels\n",
        "print(classification_report(y_test, y_pred, target_names=mlb_cuisines.classes_, zero_division=0))\n",
        "\n",
        "print(\"\\nModel evaluation complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbMCblm9U6Fy",
        "outputId": "a3ef4883-4c8e-41e0-b6c7-1f07f819c869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/multiclass.py:90: UserWarning: Label not 26 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/multiclass.py:90: UserWarning: Label not 105 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/multiclass.py:90: UserWarning: Label not 107 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Preprocessing and Model Training complete. Ready for evaluation. ---\n",
            "\n",
            "--- CELL 3: Evaluate Model Performance (Cuisine Classification) ---\n",
            "\n",
            "--- Evaluation Metrics (Threshold = 0.5) ---\n",
            "Overall Accuracy: 0.0681\n",
            "Micro-averaged Precision: 0.4975\n",
            "Micro-averaged Recall: 0.2188\n",
            "Micro-averaged F1-score: 0.3040\n",
            "\n",
            "--- Detailed Classification Report (Per Cuisine) ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "          Afghani       0.00      0.00      0.00         4\n",
            "          African       0.00      0.00      0.00         3\n",
            "         American       0.32      0.08      0.13        73\n",
            "           Andhra       0.00      0.00      0.00         2\n",
            "          Arabian       0.00      0.00      0.00         2\n",
            "        Argentine       0.00      0.00      0.00         1\n",
            "         Armenian       0.00      0.00      0.00         0\n",
            "            Asian       0.33      0.02      0.04        50\n",
            "     Asian Fusion       0.00      0.00      0.00         1\n",
            "         Assamese       0.00      0.00      0.00         0\n",
            "       Australian       0.00      0.00      0.00         1\n",
            "           Awadhi       0.00      0.00      0.00         0\n",
            "              BBQ       0.00      0.00      0.00         8\n",
            "           Bakery       0.33      0.04      0.07       135\n",
            "         Bar Food       0.00      0.00      0.00        13\n",
            "          Belgian       0.00      0.00      0.00         1\n",
            "          Bengali       0.00      0.00      0.00         7\n",
            "        Beverages       0.33      0.03      0.05        35\n",
            "           Bihari       0.00      0.00      0.00         0\n",
            "          Biryani       1.00      0.06      0.11        35\n",
            "        Brazilian       0.40      0.33      0.36         6\n",
            "        Breakfast       0.50      0.17      0.25         6\n",
            "          British       0.00      0.00      0.00         5\n",
            "       Bubble Tea       0.00      0.00      0.00         0\n",
            "           Burger       0.60      0.05      0.10        56\n",
            "          Burmese       0.00      0.00      0.00         1\n",
            "           B�_rek       0.00      0.00      0.00         1\n",
            "             Cafe       0.27      0.10      0.14       136\n",
            "            Cajun       0.00      0.00      0.00         2\n",
            "         Canadian       0.00      0.00      0.00         0\n",
            "        Cantonese       0.00      0.00      0.00         1\n",
            "        Caribbean       0.00      0.00      0.00         3\n",
            "   Charcoal Grill       0.00      0.00      0.00         2\n",
            "        Chettinad       0.00      0.00      0.00         2\n",
            "          Chinese       0.47      0.33      0.39       569\n",
            "   Coffee and Tea       0.00      0.00      0.00         2\n",
            "     Contemporary       0.00      0.00      0.00         0\n",
            "      Continental       0.39      0.21      0.27       136\n",
            "            Cuban       0.00      0.00      0.00         1\n",
            "   Cuisine Varies       0.00      0.00      0.00         0\n",
            "            Curry       0.00      0.00      0.00         2\n",
            "             Deli       0.00      0.00      0.00         0\n",
            "         Desserts       0.31      0.04      0.07       126\n",
            "          Dim Sum       0.00      0.00      0.00         0\n",
            "            Diner       0.00      0.00      0.00         0\n",
            "      Drinks Only       0.00      0.00      0.00         0\n",
            "           Durban       0.00      0.00      0.00         0\n",
            "           D�_ner       0.00      0.00      0.00         0\n",
            "         European       0.00      0.00      0.00        29\n",
            "        Fast Food       0.51      0.20      0.29       441\n",
            "         Filipino       0.00      0.00      0.00         3\n",
            "      Finger Food       0.20      0.04      0.06        26\n",
            "   Fish and Chips       0.00      0.00      0.00         0\n",
            "           French       1.00      0.17      0.29         6\n",
            "           Fusion       0.00      0.00      0.00         1\n",
            "           German       0.00      0.00      0.00         3\n",
            "             Goan       0.00      0.00      0.00         6\n",
            "Gourmet Fast Food       0.00      0.00      0.00         0\n",
            "            Greek       0.00      0.00      0.00         4\n",
            "            Grill       0.00      0.00      0.00         4\n",
            "         Gujarati       0.00      0.00      0.00         4\n",
            "         Hawaiian       0.00      0.00      0.00         1\n",
            "     Healthy Food       0.00      0.00      0.00        33\n",
            "       Hyderabadi       0.00      0.00      0.00         4\n",
            "        Ice Cream       0.00      0.00      0.00        40\n",
            "           Indian       1.00      0.40      0.57        15\n",
            "       Indonesian       0.50      0.25      0.33         4\n",
            "    International       0.00      0.00      0.00         2\n",
            "          Iranian       0.00      0.00      0.00         0\n",
            "            Irish       0.00      0.00      0.00         0\n",
            "          Italian       0.40      0.16      0.22       160\n",
            "           Izgara       0.00      0.00      0.00         0\n",
            "         Japanese       0.50      0.04      0.07        26\n",
            "           Juices       0.00      0.00      0.00         3\n",
            "         Kashmiri       0.00      0.00      0.00         6\n",
            "            Kebab       0.00      0.00      0.00         1\n",
            "           Kerala       0.00      0.00      0.00         3\n",
            "             Kiwi       0.00      0.00      0.00         1\n",
            "           Korean       0.00      0.00      0.00         3\n",
            "   Latin American       0.00      0.00      0.00         5\n",
            "         Lebanese       0.00      0.00      0.00        13\n",
            "         Lucknowi       0.00      0.00      0.00         1\n",
            "    Maharashtrian       0.00      0.00      0.00         1\n",
            "            Malay       0.00      0.00      0.00         0\n",
            "        Malaysian       0.00      0.00      0.00         5\n",
            "          Malwani       0.00      0.00      0.00         0\n",
            "      Mangalorean       0.00      0.00      0.00         1\n",
            "    Mediterranean       0.00      0.00      0.00        18\n",
            "          Mexican       0.00      0.00      0.00        36\n",
            "   Middle Eastern       0.00      0.00      0.00         7\n",
            "          Mineira       0.00      0.00      0.00         0\n",
            "           Mithai       0.40      0.08      0.13        76\n",
            "Modern Australian       0.00      0.00      0.00         0\n",
            "    Modern Indian       0.00      0.00      0.00         3\n",
            "         Moroccan       0.00      0.00      0.00         1\n",
            "          Mughlai       0.24      0.05      0.08       222\n",
            "             Naga       0.00      0.00      0.00         2\n",
            "         Nepalese       0.00      0.00      0.00         2\n",
            "     New American       0.00      0.00      0.00         0\n",
            "    North Eastern       0.00      0.00      0.00         1\n",
            "     North Indian       0.61      0.56      0.58       813\n",
            "            Oriya       0.00      0.00      0.00         0\n",
            "        Pakistani       0.00      0.00      0.00         3\n",
            "            Parsi       0.00      0.00      0.00         0\n",
            "       Patisserie       0.00      0.00      0.00         0\n",
            "        Peranakan       0.00      0.00      0.00         1\n",
            "          Persian       0.00      0.00      0.00         0\n",
            "         Peruvian       0.00      0.00      0.00         1\n",
            "            Pizza       0.60      0.08      0.14        78\n",
            "       Portuguese       0.00      0.00      0.00         2\n",
            "         Pub Food       0.00      0.00      0.00         0\n",
            "       Rajasthani       0.00      0.00      0.00         8\n",
            "            Ramen       0.00      0.00      0.00         0\n",
            "        Raw Meats       0.00      0.00      0.00        24\n",
            "  Restaurant Cafe       0.00      0.00      0.00         1\n",
            "            Salad       0.00      0.00      0.00        24\n",
            "         Sandwich       0.00      0.00      0.00        12\n",
            "         Scottish       0.00      0.00      0.00         1\n",
            "          Seafood       0.33      0.05      0.09        39\n",
            "      Singaporean       0.00      0.00      0.00         2\n",
            "        Soul Food       0.00      0.00      0.00         0\n",
            "    South African       0.00      0.00      0.00         2\n",
            "   South American       0.00      0.00      0.00         1\n",
            "     South Indian       0.29      0.04      0.07       117\n",
            "         Southern       0.50      0.33      0.40         3\n",
            "     Southwestern       0.00      0.00      0.00         0\n",
            "          Spanish       0.00      0.00      0.00         3\n",
            "       Sri Lankan       0.00      0.00      0.00         0\n",
            "            Steak       0.50      0.13      0.21        15\n",
            "      Street Food       0.31      0.09      0.14       113\n",
            "            Sunda       0.00      0.00      0.00         1\n",
            "            Sushi       0.00      0.00      0.00        13\n",
            "        Taiwanese       0.00      0.00      0.00         1\n",
            "            Tapas       0.00      0.00      0.00         1\n",
            "              Tea       0.00      0.00      0.00         8\n",
            "         Teriyaki       0.00      0.00      0.00         1\n",
            "          Tex-Mex       0.00      0.00      0.00         2\n",
            "             Thai       0.10      0.02      0.03        50\n",
            "          Tibetan       1.00      0.17      0.29         6\n",
            "          Turkish       0.00      0.00      0.00         2\n",
            "    Turkish Pizza       0.00      0.00      0.00         1\n",
            "       Vegetarian       0.00      0.00      0.00         2\n",
            "       Vietnamese       0.00      0.00      0.00         7\n",
            "          Western       0.00      0.00      0.00         2\n",
            "    World Cuisine       0.00      0.00      0.00         1\n",
            "\n",
            "        micro avg       0.50      0.22      0.30      4012\n",
            "        macro avg       0.10      0.03      0.04      4012\n",
            "     weighted avg       0.40      0.22      0.26      4012\n",
            "      samples avg       0.31      0.21      0.23      4012\n",
            "\n",
            "\n",
            "Model evaluation complete.\n"
          ]
        }
      ]
    }
  ]
}